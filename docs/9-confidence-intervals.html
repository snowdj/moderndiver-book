<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 9 Confidence Intervals | Statistical Inference via Data Science</title>
  <meta name="description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 9 Confidence Intervals | Statistical Inference via Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://moderndive.com/" />
  <meta property="og:image" content="https://moderndive.com/images/logos/book_cover.png" />
  <meta property="og:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="github-repo" content="moderndive/moderndive_book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Confidence Intervals | Statistical Inference via Data Science" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic textbook for teaching statistical inference using tidyverse data science tools." />
  <meta name="twitter:image" content="https://moderndive.com/images/logos/book_cover.png" />

<meta name="author" content="Chester Ismay and Albert Y. Kim">


<meta name="date" content="2019-03-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="images/logos/favicons/apple-touch-icon.png">
  <link rel="shortcut icon" href="images/logos/favicons/favicon.ico" type="image/x-icon">
<link rel="prev" href="8-sampling.html">
<link rel="next" href="10-hypothesis-testing.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#sec:intro-for-students"><i class="fa fa-check"></i><b>1.1</b> Introduction for students</a><ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#subsec:learning-goals"><i class="fa fa-check"></i><b>1.1.1</b> What you will learn from this book</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#subsec:pipeline"><i class="fa fa-check"></i><b>1.1.2</b> Data/science pipeline</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#subsec:reproducible"><i class="fa fa-check"></i><b>1.1.3</b> Reproducible research</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#final-note-for-students"><i class="fa fa-check"></i><b>1.1.4</b> Final note for students</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#sec:intro-instructors"><i class="fa fa-check"></i><b>1.2</b> Introduction for instructors</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i><b>1.2.1</b> Who is this book for?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#datacamp"><i class="fa fa-check"></i><b>1.3</b> DataCamp</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#sec:connect-contribute"><i class="fa fa-check"></i><b>1.4</b> Connect and contribute</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#sec:about-book"><i class="fa fa-check"></i><b>1.5</b> About this book</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#sec:about-authors"><i class="fa fa-check"></i><b>1.6</b> About the authors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-getting-started.html"><a href="2-getting-started.html"><i class="fa fa-check"></i><b>2</b> Getting Started with Data in R</a><ul>
<li class="chapter" data-level="2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#r-rstudio"><i class="fa fa-check"></i><b>2.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-getting-started.html"><a href="2-getting-started.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>2.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-getting-started.html"><a href="2-getting-started.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>2.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#code"><i class="fa fa-check"></i><b>2.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-getting-started.html"><a href="2-getting-started.html#programming-concepts"><i class="fa fa-check"></i><b>2.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-getting-started.html"><a href="2-getting-started.html#errors-warnings-and-messages"><i class="fa fa-check"></i><b>2.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#tips-on-learning-to-code"><i class="fa fa-check"></i><b>2.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-getting-started.html"><a href="2-getting-started.html#packages"><i class="fa fa-check"></i><b>2.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-getting-started.html"><a href="2-getting-started.html#package-installation"><i class="fa fa-check"></i><b>2.3.1</b> Package installation</a></li>
<li class="chapter" data-level="2.3.2" data-path="2-getting-started.html"><a href="2-getting-started.html#package-loading"><i class="fa fa-check"></i><b>2.3.2</b> Package loading</a></li>
<li class="chapter" data-level="2.3.3" data-path="2-getting-started.html"><a href="2-getting-started.html#package-use"><i class="fa fa-check"></i><b>2.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13"><i class="fa fa-check"></i><b>2.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-getting-started.html"><a href="2-getting-started.html#nycflights13-package"><i class="fa fa-check"></i><b>2.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="2.4.2" data-path="2-getting-started.html"><a href="2-getting-started.html#flights-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-getting-started.html"><a href="2-getting-started.html#exploredataframes"><i class="fa fa-check"></i><b>2.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="2.4.4" data-path="2-getting-started.html"><a href="2-getting-started.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>2.4.4</b> Identification &amp; measurement variables</a></li>
<li class="chapter" data-level="2.4.5" data-path="2-getting-started.html"><a href="2-getting-started.html#help-files"><i class="fa fa-check"></i><b>2.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-getting-started.html"><a href="2-getting-started.html#conclusion"><i class="fa fa-check"></i><b>2.5</b> Conclusion</a><ul>
<li class="chapter" data-level="2.5.1" data-path="2-getting-started.html"><a href="2-getting-started.html#additional-resources"><i class="fa fa-check"></i><b>2.5.1</b> Additional resources</a></li>
<li class="chapter" data-level="2.5.2" data-path="2-getting-started.html"><a href="2-getting-started.html#whats-to-come"><i class="fa fa-check"></i><b>2.5.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Data Science via the tidyverse</b></span></li>
<li class="chapter" data-level="3" data-path="3-viz.html"><a href="3-viz.html"><i class="fa fa-check"></i><b>3</b> Data Visualization</a><ul>
<li class="chapter" data-level="" data-path="3-viz.html"><a href="3-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="3.1" data-path="3-viz.html"><a href="3-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>3.1</b> The Grammar of Graphics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-viz.html"><a href="3-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>3.1.1</b> Components of the Grammar</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-viz.html"><a href="3-viz.html#gapminder"><i class="fa fa-check"></i><b>3.1.2</b> Gapminder data</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-viz.html"><a href="3-viz.html#other-components"><i class="fa fa-check"></i><b>3.1.3</b> Other components</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-viz.html"><a href="3-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>3.1.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-viz.html"><a href="3-viz.html#FiveNG"><i class="fa fa-check"></i><b>3.2</b> Five Named Graphs - The 5NG</a></li>
<li class="chapter" data-level="3.3" data-path="3-viz.html"><a href="3-viz.html#scatterplots"><i class="fa fa-check"></i><b>3.3</b> 5NG#1: Scatterplots</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-viz.html"><a href="3-viz.html#geompoint"><i class="fa fa-check"></i><b>3.3.1</b> Scatterplots via geom_point</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-viz.html"><a href="3-viz.html#overplotting"><i class="fa fa-check"></i><b>3.3.2</b> Over-plotting</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-viz.html"><a href="3-viz.html#summary"><i class="fa fa-check"></i><b>3.3.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-viz.html"><a href="3-viz.html#linegraphs"><i class="fa fa-check"></i><b>3.4</b> 5NG#2: Linegraphs</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-viz.html"><a href="3-viz.html#geomline"><i class="fa fa-check"></i><b>3.4.1</b> Linegraphs via geom_line</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-viz.html"><a href="3-viz.html#summary-1"><i class="fa fa-check"></i><b>3.4.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-viz.html"><a href="3-viz.html#histograms"><i class="fa fa-check"></i><b>3.5</b> 5NG#3: Histograms</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-viz.html"><a href="3-viz.html#geomhistogram"><i class="fa fa-check"></i><b>3.5.1</b> Histograms via geom_histogram</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-viz.html"><a href="3-viz.html#adjustbins"><i class="fa fa-check"></i><b>3.5.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-viz.html"><a href="3-viz.html#summary-2"><i class="fa fa-check"></i><b>3.5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3-viz.html"><a href="3-viz.html#facets"><i class="fa fa-check"></i><b>3.6</b> Facets</a></li>
<li class="chapter" data-level="3.7" data-path="3-viz.html"><a href="3-viz.html#boxplots"><i class="fa fa-check"></i><b>3.7</b> 5NG#4: Boxplots</a><ul>
<li class="chapter" data-level="3.7.1" data-path="3-viz.html"><a href="3-viz.html#geomboxplot"><i class="fa fa-check"></i><b>3.7.1</b> Boxplots via geom_boxplot</a></li>
<li class="chapter" data-level="3.7.2" data-path="3-viz.html"><a href="3-viz.html#summary-3"><i class="fa fa-check"></i><b>3.7.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="3-viz.html"><a href="3-viz.html#geombar"><i class="fa fa-check"></i><b>3.8</b> 5NG#5: Barplots</a><ul>
<li class="chapter" data-level="3.8.1" data-path="3-viz.html"><a href="3-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>3.8.1</b> Barplots via geom_bar or geom_col</a></li>
<li class="chapter" data-level="3.8.2" data-path="3-viz.html"><a href="3-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>3.8.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="3.8.3" data-path="3-viz.html"><a href="3-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>3.8.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="3.8.4" data-path="3-viz.html"><a href="3-viz.html#summary-4"><i class="fa fa-check"></i><b>3.8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="3-viz.html"><a href="3-viz.html#conclusion-1"><i class="fa fa-check"></i><b>3.9</b> Conclusion</a><ul>
<li class="chapter" data-level="3.9.1" data-path="3-viz.html"><a href="3-viz.html#summary-table"><i class="fa fa-check"></i><b>3.9.1</b> Summary table</a></li>
<li class="chapter" data-level="3.9.2" data-path="3-viz.html"><a href="3-viz.html#argument-specification"><i class="fa fa-check"></i><b>3.9.2</b> Argument specification</a></li>
<li class="chapter" data-level="3.9.3" data-path="3-viz.html"><a href="3-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>3.9.3</b> Additional resources</a></li>
<li class="chapter" data-level="3.9.4" data-path="3-viz.html"><a href="3-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>3.9.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-wrangling.html"><a href="4-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a><ul>
<li class="chapter" data-level="" data-path="4-wrangling.html"><a href="4-wrangling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#piping"><i class="fa fa-check"></i><b>4.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-wrangling.html"><a href="4-wrangling.html#filter"><i class="fa fa-check"></i><b>4.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="4.3" data-path="4-wrangling.html"><a href="4-wrangling.html#summarize"><i class="fa fa-check"></i><b>4.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="4.4" data-path="4-wrangling.html"><a href="4-wrangling.html#groupby"><i class="fa fa-check"></i><b>4.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-wrangling.html"><a href="4-wrangling.html#mutate"><i class="fa fa-check"></i><b>4.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="4.6" data-path="4-wrangling.html"><a href="4-wrangling.html#arrange"><i class="fa fa-check"></i><b>4.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="4.7" data-path="4-wrangling.html"><a href="4-wrangling.html#joins"><i class="fa fa-check"></i><b>4.7</b> <code>join</code> data frames</a><ul>
<li class="chapter" data-level="4.7.1" data-path="4-wrangling.html"><a href="4-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>4.7.1</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="4.7.2" data-path="4-wrangling.html"><a href="4-wrangling.html#diff-key"><i class="fa fa-check"></i><b>4.7.2</b> Different “key” variable names</a></li>
<li class="chapter" data-level="4.7.3" data-path="4-wrangling.html"><a href="4-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>4.7.3</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="4.7.4" data-path="4-wrangling.html"><a href="4-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>4.7.4</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4-wrangling.html"><a href="4-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>4.8</b> Other verbs</a><ul>
<li class="chapter" data-level="4.8.1" data-path="4-wrangling.html"><a href="4-wrangling.html#select"><i class="fa fa-check"></i><b>4.8.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="4.8.2" data-path="4-wrangling.html"><a href="4-wrangling.html#rename"><i class="fa fa-check"></i><b>4.8.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="4.8.3" data-path="4-wrangling.html"><a href="4-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>4.8.3</b> <code>top_n</code> values of a variable</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="4-wrangling.html"><a href="4-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>4.9</b> Conclusion</a><ul>
<li class="chapter" data-level="4.9.1" data-path="4-wrangling.html"><a href="4-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>4.9.1</b> Summary table</a></li>
<li class="chapter" data-level="4.9.2" data-path="4-wrangling.html"><a href="4-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>4.9.2</b> Additional resources</a></li>
<li class="chapter" data-level="4.9.3" data-path="4-wrangling.html"><a href="4-wrangling.html#whats-to-come-1"><i class="fa fa-check"></i><b>4.9.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-tidy.html"><a href="5-tidy.html"><i class="fa fa-check"></i><b>5</b> Data Importing &amp; “Tidy” Data</a><ul>
<li class="chapter" data-level="" data-path="5-tidy.html"><a href="5-tidy.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="5.1" data-path="5-tidy.html"><a href="5-tidy.html#csv"><i class="fa fa-check"></i><b>5.1</b> Importing data</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-tidy.html"><a href="5-tidy.html#using-the-console"><i class="fa fa-check"></i><b>5.1.1</b> Using the console</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-tidy.html"><a href="5-tidy.html#using-rstudios-interface"><i class="fa fa-check"></i><b>5.1.2</b> Using RStudio’s interface</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-tidy.html"><a href="5-tidy.html#tidy-data-ex"><i class="fa fa-check"></i><b>5.2</b> Tidy data</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-tidy.html"><a href="5-tidy.html#definition-of-tidy-data"><i class="fa fa-check"></i><b>5.2.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-tidy.html"><a href="5-tidy.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>5.2.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-tidy.html"><a href="5-tidy.html#nycflights13-package-1"><i class="fa fa-check"></i><b>5.2.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-tidy.html"><a href="5-tidy.html#case-study-tidy"><i class="fa fa-check"></i><b>5.3</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="5.4" data-path="5-tidy.html"><a href="5-tidy.html#conclusion-3"><i class="fa fa-check"></i><b>5.4</b> Conclusion</a><ul>
<li class="chapter" data-level="5.4.1" data-path="5-tidy.html"><a href="5-tidy.html#tidyverse-package"><i class="fa fa-check"></i><b>5.4.1</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="5.4.2" data-path="5-tidy.html"><a href="5-tidy.html#additional-resources-3"><i class="fa fa-check"></i><b>5.4.2</b> Additional resources</a></li>
<li class="chapter" data-level="5.4.3" data-path="5-tidy.html"><a href="5-tidy.html#whats-to-come-2"><i class="fa fa-check"></i><b>5.4.3</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Data Modeling via moderndive</b></span></li>
<li class="chapter" data-level="6" data-path="6-regression.html"><a href="6-regression.html"><i class="fa fa-check"></i><b>6</b> Basic Regression</a><ul>
<li class="chapter" data-level="" data-path="6-regression.html"><a href="6-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="6.1" data-path="6-regression.html"><a href="6-regression.html#model1"><i class="fa fa-check"></i><b>6.1</b> One numerical explanatory variable</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-regression.html"><a href="6-regression.html#model1EDA"><i class="fa fa-check"></i><b>6.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-regression.html"><a href="6-regression.html#model1table"><i class="fa fa-check"></i><b>6.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-regression.html"><a href="6-regression.html#model1points"><i class="fa fa-check"></i><b>6.1.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-regression.html"><a href="6-regression.html#model2"><i class="fa fa-check"></i><b>6.2</b> One categorical explanatory variable</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-regression.html"><a href="6-regression.html#model2EDA"><i class="fa fa-check"></i><b>6.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-regression.html"><a href="6-regression.html#model2table"><i class="fa fa-check"></i><b>6.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-regression.html"><a href="6-regression.html#model2points"><i class="fa fa-check"></i><b>6.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-regression.html"><a href="6-regression.html#related-topics"><i class="fa fa-check"></i><b>6.3</b> Related topics</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-regression.html"><a href="6-regression.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>6.3.1</b> Correlation is not necessarily causation</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-regression.html"><a href="6-regression.html#leastsquares"><i class="fa fa-check"></i><b>6.3.2</b> Best fitting line</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-regression.html"><a href="6-regression.html#underthehood"><i class="fa fa-check"></i><b>6.3.3</b> <code>get_regression_x()</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-regression.html"><a href="6-regression.html#conclusion-4"><i class="fa fa-check"></i><b>6.4</b> Conclusion</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-regression.html"><a href="6-regression.html#additional-resources-basic-regression"><i class="fa fa-check"></i><b>6.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-regression.html"><a href="6-regression.html#whats-to-come-4"><i class="fa fa-check"></i><b>6.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="7.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4"><i class="fa fa-check"></i><b>7.1</b> One numerical &amp; one categorical explanatory variable</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>7.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>7.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>7.1.3</b> Parallel slopes model</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>7.1.4</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3"><i class="fa fa-check"></i><b>7.2</b> Two numerical explanatory variables</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>7.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>7.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>7.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#related-topics-1"><i class="fa fa-check"></i><b>7.3</b> Related topics</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>7.3.1</b> Model selection</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>7.3.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>7.3.3</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#conclusion-5"><i class="fa fa-check"></i><b>7.4</b> Conclusion</a><ul>
<li class="chapter" data-level="7.4.1" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#additional-resources-4"><i class="fa fa-check"></i><b>7.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="7.4.2" data-path="7-multiple-regression.html"><a href="7-multiple-regression.html#whats-to-come-5"><i class="fa fa-check"></i><b>7.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Statistical inference via infer</b></span></li>
<li class="chapter" data-level="8" data-path="8-sampling.html"><a href="8-sampling.html"><i class="fa fa-check"></i><b>8</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="8-sampling.html"><a href="8-sampling.html#needed-packages-5"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="8.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>8.1</b> Sampling activity</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-sampling.html"><a href="8-sampling.html#what-proportion-of-this-bowls-balls-are-red"><i class="fa fa-check"></i><b>8.1.1</b> What proportion of this bowl’s balls are red?</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>8.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="8.1.3" data-path="8-sampling.html"><a href="8-sampling.html#student-shovels"><i class="fa fa-check"></i><b>8.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="8.1.4" data-path="8-sampling.html"><a href="8-sampling.html#what-are-we-doing-here"><i class="fa fa-check"></i><b>8.1.4</b> What are we doing here?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>8.2</b> Computer simulation of sampling</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>8.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="8.2.2" data-path="8-sampling.html"><a href="8-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>8.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="8.2.3" data-path="8-sampling.html"><a href="8-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>8.2.3</b> Using the virtual shovel 1000 times</a></li>
<li class="chapter" data-level="8.2.4" data-path="8-sampling.html"><a href="8-sampling.html#different-shovels"><i class="fa fa-check"></i><b>8.2.4</b> Using different shovels</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-sampling.html"><a href="8-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>8.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="8.3.1" data-path="8-sampling.html"><a href="8-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>8.3.1</b> Terminology &amp; notation</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-sampling.html"><a href="8-sampling.html#statistical-definitions"><i class="fa fa-check"></i><b>8.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-sampling.html"><a href="8-sampling.html#the-moral-of-the-story"><i class="fa fa-check"></i><b>8.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-sampling.html"><a href="8-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>8.4</b> Case study: Polls</a></li>
<li class="chapter" data-level="8.5" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion"><i class="fa fa-check"></i><b>8.5</b> Conclusion</a><ul>
<li class="chapter" data-level="8.5.1" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>8.5.1</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="8.5.2" data-path="8-sampling.html"><a href="8-sampling.html#sampling-conclusion-table"><i class="fa fa-check"></i><b>8.5.2</b> Summary table</a></li>
<li class="chapter" data-level="8.5.3" data-path="8-sampling.html"><a href="8-sampling.html#additional-resources-5"><i class="fa fa-check"></i><b>8.5.3</b> Additional resources</a></li>
<li class="chapter" data-level="8.5.4" data-path="8-sampling.html"><a href="8-sampling.html#whats-to-come-6"><i class="fa fa-check"></i><b>8.5.4</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html"><i class="fa fa-check"></i><b>9</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#needed-packages-6"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-activity"><i class="fa fa-check"></i><b>9.1</b> Resampling activity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#what-is-the-average-year-of-circulated-us-pennies-in-2019"><i class="fa fa-check"></i><b>9.1.1</b> What is the average year of circulated US pennies in 2019?</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-resampling-once"><i class="fa fa-check"></i><b>9.1.2</b> Using resampling once</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>9.1.3</b> Using resampling 33 times</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#whats-the-plan"><i class="fa fa-check"></i><b>9.1.4</b> What’s the plan?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>9.2</b> Computer simulation of resampling</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-the-virtual-resample-once"><i class="fa fa-check"></i><b>9.2.1</b> Using the virtual resample once</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-the-virtual-resample-33-times"><i class="fa fa-check"></i><b>9.2.2</b> Using the virtual resample 33 times</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#using-the-virtual-resample-1000-times"><i class="fa fa-check"></i><b>9.2.3</b> Using the virtual resample 1000 times</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>9.3</b> Confidence interval build-up</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>9.3.1</b> The percentile method</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-standard-error-method"><i class="fa fa-check"></i><b>9.3.2</b> The standard error method</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-process"><i class="fa fa-check"></i><b>9.4</b> The bootstrapping framework</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-original-workflow-needed-for-this"><i class="fa fa-check"></i><b>9.4.1</b> The original workflow needed for this</a></li>
<li class="chapter" data-level="9.4.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-infer-package-for-statistical-inference"><i class="fa fa-check"></i><b>9.4.2</b> The infer package for statistical inference</a></li>
<li class="chapter" data-level="9.4.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#infer-ci"><i class="fa fa-check"></i><b>9.4.3</b> Building confidence intervals with the infer package</a></li>
<li class="chapter" data-level="9.4.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#percentile-method-infer"><i class="fa fa-check"></i><b>9.4.4</b> The percentile method with infer</a></li>
<li class="chapter" data-level="9.4.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-standard-error-method-with-infer"><i class="fa fa-check"></i><b>9.4.5</b> The standard error method with infer</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>9.5</b> Case study: Revisiting the red ball example</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#observed-statistic"><i class="fa fa-check"></i><b>9.5.1</b> Observed statistic</a></li>
<li class="chapter" data-level="9.5.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#one-prop-boot"><i class="fa fa-check"></i><b>9.5.2</b> Bootstrap distribution for one proportion</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>9.6</b> Interpreting the confidence interval</a><ul>
<li class="chapter" data-level="" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#the-width-of-confidence-intervals"><i class="fa fa-check"></i>The width of confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>9.7</b> Case study: Comparing two proportions</a><ul>
<li class="chapter" data-level="9.7.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#compute-the-point-estimate"><i class="fa fa-check"></i><b>9.7.1</b> Compute the point estimate</a></li>
<li class="chapter" data-level="9.7.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#bootstrap-distribution"><i class="fa fa-check"></i><b>9.7.2</b> Bootstrap distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>9.8</b> Conclusion</a><ul>
<li class="chapter" data-level="9.8.1" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#comparing-bootstrap-and-sampling-distributions"><i class="fa fa-check"></i><b>9.8.1</b> Comparing bootstrap and sampling distributions</a></li>
<li class="chapter" data-level="9.8.2" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#theory-ci"><i class="fa fa-check"></i><b>9.8.2</b> Theory-based confidence intervals</a></li>
<li class="chapter" data-level="9.8.3" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#ci-conclusion-table"><i class="fa fa-check"></i><b>9.8.3</b> Summary table</a></li>
<li class="chapter" data-level="9.8.4" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#additional-resources-6"><i class="fa fa-check"></i><b>9.8.4</b> Additional resources</a></li>
<li class="chapter" data-level="9.8.5" data-path="9-confidence-intervals.html"><a href="9-confidence-intervals.html#whats-to-come-7"><i class="fa fa-check"></i><b>9.8.5</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#needed-packages-7"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-activity"><i class="fa fa-check"></i><b>10.1</b> Hypothesis testing activity</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#question-of-interest"><i class="fa fa-check"></i><b>10.1.1</b> Question of interest</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#what-did-we-actually-observe"><i class="fa fa-check"></i><b>10.1.2</b> What did we actually observe?</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#using-permuting-once"><i class="fa fa-check"></i><b>10.1.3</b> Using permuting once</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#using-permuting-33-times"><i class="fa fa-check"></i><b>10.1.4</b> Using permuting 33 times</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-infer"><i class="fa fa-check"></i><b>10.2</b> Hypothesis testing with infer</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#revisiting-the-infer-verb-framework"><i class="fa fa-check"></i><b>10.2.1</b> Revisiting the infer verb framework</a></li>
<li class="chapter" data-level="10.2.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#the-infer-pipeline-for-the-activity"><i class="fa fa-check"></i><b>10.2.2</b> The <code>infer</code> pipeline for the activity</a></li>
<li class="chapter" data-level="10.2.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#only-one-test"><i class="fa fa-check"></i><b>10.2.3</b> The “There Is Only One Test” framework</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#p-value"><i class="fa fa-check"></i><b>10.3</b> The p-value</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#corresponding-confidence-interval"><i class="fa fa-check"></i><b>10.3.1</b> Corresponding confidence interval</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#summary-5"><i class="fa fa-check"></i><b>10.3.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-interpretation"><i class="fa fa-check"></i><b>10.4</b> Interpretation of hypothesis testing results</a><ul>
<li class="chapter" data-level="10.4.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#trial"><i class="fa fa-check"></i><b>10.4.1</b> Criminal trial analogy</a></li>
<li class="chapter" data-level="10.4.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#types-of-errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>10.4.2</b> Types of errors in hypothesis testing</a></li>
<li class="chapter" data-level="10.4.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#statistical-significance"><i class="fa fa-check"></i><b>10.4.3</b> Statistical significance</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-case-study"><i class="fa fa-check"></i><b>10.5</b> Case study: comparing two means</a><ul>
<li class="chapter" data-level="10.5.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#randomizationpermutation"><i class="fa fa-check"></i><b>10.5.1</b> Randomization/permutation</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#comparing-action-and-romance-movies"><i class="fa fa-check"></i><b>10.5.2</b> Comparing action and romance movies</a></li>
<li class="chapter" data-level="10.5.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#sampling-rightarrow-randomization"><i class="fa fa-check"></i><b>10.5.3</b> Sampling <span class="math inline">\(\rightarrow\)</span> randomization</a></li>
<li class="chapter" data-level="10.5.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#data"><i class="fa fa-check"></i><b>10.5.4</b> Data</a></li>
<li class="chapter" data-level="10.5.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#model-of-h_0"><i class="fa fa-check"></i><b>10.5.5</b> Model of <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="10.5.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#test-statistic-delta"><i class="fa fa-check"></i><b>10.5.6</b> Test statistic <span class="math inline">\(\delta\)</span></a></li>
<li class="chapter" data-level="10.5.7" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#observed-effect-delta"><i class="fa fa-check"></i><b>10.5.7</b> Observed effect <span class="math inline">\(\delta^*\)</span></a></li>
<li class="chapter" data-level="10.5.8" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#simulated-data"><i class="fa fa-check"></i><b>10.5.8</b> Simulated data</a></li>
<li class="chapter" data-level="10.5.9" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#distribution-of-delta-under-h_0"><i class="fa fa-check"></i><b>10.5.9</b> Distribution of <span class="math inline">\(\delta\)</span> under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="10.5.10" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#the-p-value"><i class="fa fa-check"></i><b>10.5.10</b> The p-value</a></li>
<li class="chapter" data-level="10.5.11" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#corresponding-confidence-interval-1"><i class="fa fa-check"></i><b>10.5.11</b> Corresponding confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#conclusion-6"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a><ul>
<li class="chapter" data-level="10.6.1" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#when-inference-is-not-needed"><i class="fa fa-check"></i><b>10.6.1</b> When inference is not needed</a></li>
<li class="chapter" data-level="10.6.2" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#problems-with-p-values"><i class="fa fa-check"></i><b>10.6.2</b> Problems with p-values</a></li>
<li class="chapter" data-level="10.6.3" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#comparing-confidence-intervals-and-hypothesis-tests"><i class="fa fa-check"></i><b>10.6.3</b> Comparing confidence intervals and hypothesis tests</a></li>
<li class="chapter" data-level="10.6.4" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#ht-conclusion-table"><i class="fa fa-check"></i><b>10.6.4</b> Summary table</a></li>
<li class="chapter" data-level="10.6.5" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#theory-hypo"><i class="fa fa-check"></i><b>10.6.5</b> Building theory-based methods using computation</a></li>
<li class="chapter" data-level="10.6.6" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#additional-resources-7"><i class="fa fa-check"></i><b>10.6.6</b> Additional resources</a></li>
<li class="chapter" data-level="10.6.7" data-path="10-hypothesis-testing.html"><a href="10-hypothesis-testing.html#whats-to-come-8"><i class="fa fa-check"></i><b>10.6.7</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html"><i class="fa fa-check"></i><b>11</b> Inference for Regression</a><ul>
<li class="chapter" data-level="" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#needed-packages-8"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="11.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#simulation-based-inference-for-regression"><i class="fa fa-check"></i><b>11.1</b> Simulation-based Inference for Regression</a><ul>
<li class="chapter" data-level="11.1.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#data-1"><i class="fa fa-check"></i><b>11.1.1</b> Data</a></li>
<li class="chapter" data-level="11.1.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#test-statistic-delta-1"><i class="fa fa-check"></i><b>11.1.2</b> Test statistic <span class="math inline">\(\delta\)</span></a></li>
<li class="chapter" data-level="11.1.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#observed-effect-delta-1"><i class="fa fa-check"></i><b>11.1.3</b> Observed effect <span class="math inline">\(\delta^*\)</span></a></li>
<li class="chapter" data-level="11.1.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model-of-h_0-1"><i class="fa fa-check"></i><b>11.1.4</b> Model of <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="11.1.5" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#simulated-data-1"><i class="fa fa-check"></i><b>11.1.5</b> Simulated data</a></li>
<li class="chapter" data-level="11.1.6" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#distribution-of-delta-under-h_0-1"><i class="fa fa-check"></i><b>11.1.6</b> Distribution of <span class="math inline">\(\delta\)</span> under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="11.1.7" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#the-p-value-1"><i class="fa fa-check"></i><b>11.1.7</b> The p-value</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#bootstrapping-for-the-regression-slope"><i class="fa fa-check"></i><b>11.2</b> Bootstrapping for the regression slope</a></li>
<li class="chapter" data-level="11.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#inference-for-multiple-regression"><i class="fa fa-check"></i><b>11.3</b> Inference for multiple regression</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#refresher-professor-evaluations-data"><i class="fa fa-check"></i><b>11.3.1</b> Refresher: Professor evaluations data</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#refresher-visualizations"><i class="fa fa-check"></i><b>11.3.2</b> Refresher: Visualizations</a></li>
<li class="chapter" data-level="11.3.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#refresher-regression-tables"><i class="fa fa-check"></i><b>11.3.3</b> Refresher: Regression tables</a></li>
<li class="chapter" data-level="11.3.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#script-of-r-code"><i class="fa fa-check"></i><b>11.3.4</b> Script of R code</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#residual-analysis"><i class="fa fa-check"></i><b>11.4</b> Residual analysis</a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model1residuals"><i class="fa fa-check"></i><b>11.4.1</b> Residual analysis</a></li>
<li class="chapter" data-level="11.4.2" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model2residuals"><i class="fa fa-check"></i><b>11.4.2</b> Residual analysis</a></li>
<li class="chapter" data-level="11.4.3" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model3residuals"><i class="fa fa-check"></i><b>11.4.3</b> Residual analysis</a></li>
<li class="chapter" data-level="11.4.4" data-path="11-inference-for-regression.html"><a href="11-inference-for-regression.html#model4residuals"><i class="fa fa-check"></i><b>11.4.4</b> Residual analysis</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Conclusion</b></span></li>
<li class="chapter" data-level="12" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html"><i class="fa fa-check"></i><b>12</b> Thinking with Data</a><ul>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#needed-packages-9"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="12.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#seattle-house-prices"><i class="fa fa-check"></i><b>12.1</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>12.1.1</b> Exploratory data analysis (EDA)</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#log10-transformations"><i class="fa fa-check"></i><b>12.1.2</b> log10 transformations</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#eda-part-ii"><i class="fa fa-check"></i><b>12.1.3</b> EDA Part II</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-regression"><i class="fa fa-check"></i><b>12.1.4</b> Regression modeling</a></li>
<li class="chapter" data-level="12.1.5" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>12.1.5</b> Making predictions</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#data-journalism"><i class="fa fa-check"></i><b>12.2</b> Case study: Effective data storytelling</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#bechdel-test-for-hollywood-gender-representation"><i class="fa fa-check"></i><b>12.2.1</b> Bechdel test for Hollywood gender representation</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#us-births-in-1999"><i class="fa fa-check"></i><b>12.2.2</b> US Births in 1999</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#other-examples"><i class="fa fa-check"></i><b>12.2.3</b> Other examples</a></li>
<li class="chapter" data-level="12.2.4" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#script-of-r-code-1"><i class="fa fa-check"></i><b>12.2.4</b> Script of R code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="12-thinking-with-data.html"><a href="12-thinking-with-data.html#concluding-remarks"><i class="fa fa-check"></i>Concluding remarks</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-appendixA.html"><a href="A-appendixA.html"><i class="fa fa-check"></i><b>A</b> Statistical Background</a><ul>
<li class="chapter" data-level="A.1" data-path="A-appendixA.html"><a href="A-appendixA.html#basic-statistical-terms"><i class="fa fa-check"></i><b>A.1</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="A.1.1" data-path="A-appendixA.html"><a href="A-appendixA.html#mean"><i class="fa fa-check"></i><b>A.1.1</b> Mean</a></li>
<li class="chapter" data-level="A.1.2" data-path="A-appendixA.html"><a href="A-appendixA.html#median"><i class="fa fa-check"></i><b>A.1.2</b> Median</a></li>
<li class="chapter" data-level="A.1.3" data-path="A-appendixA.html"><a href="A-appendixA.html#standard-deviation"><i class="fa fa-check"></i><b>A.1.3</b> Standard deviation</a></li>
<li class="chapter" data-level="A.1.4" data-path="A-appendixA.html"><a href="A-appendixA.html#five-number-summary"><i class="fa fa-check"></i><b>A.1.4</b> Five-number summary</a></li>
<li class="chapter" data-level="A.1.5" data-path="A-appendixA.html"><a href="A-appendixA.html#distribution"><i class="fa fa-check"></i><b>A.1.5</b> Distribution</a></li>
<li class="chapter" data-level="A.1.6" data-path="A-appendixA.html"><a href="A-appendixA.html#outliers"><i class="fa fa-check"></i><b>A.1.6</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="A-appendixA.html"><a href="A-appendixA.html#normal-curve"><i class="fa fa-check"></i><b>A.2</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-appendixB.html"><a href="B-appendixB.html"><i class="fa fa-check"></i><b>B</b> Inference Examples</a><ul>
<li class="chapter" data-level="" data-path="B-appendixB.html"><a href="B-appendixB.html#needed-packages-10"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="B.1" data-path="B-appendixB.html"><a href="B-appendixB.html#inference-mind-map"><i class="fa fa-check"></i><b>B.1</b> Inference mind map</a></li>
<li class="chapter" data-level="B.2" data-path="B-appendixB.html"><a href="B-appendixB.html#one-mean"><i class="fa fa-check"></i><b>B.2</b> One mean</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement"><i class="fa fa-check"></i><b>B.2.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses"><i class="fa fa-check"></i><b>B.2.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.2.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data"><i class="fa fa-check"></i><b>B.2.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.2.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods"><i class="fa fa-check"></i><b>B.2.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.2.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods"><i class="fa fa-check"></i><b>B.2.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.2.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results"><i class="fa fa-check"></i><b>B.2.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="B-appendixB.html"><a href="B-appendixB.html#one-proportion"><i class="fa fa-check"></i><b>B.3</b> One proportion</a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-1"><i class="fa fa-check"></i><b>B.3.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-1"><i class="fa fa-check"></i><b>B.3.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.3.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-1"><i class="fa fa-check"></i><b>B.3.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.3.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-1"><i class="fa fa-check"></i><b>B.3.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.3.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-1"><i class="fa fa-check"></i><b>B.3.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.3.6" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-1"><i class="fa fa-check"></i><b>B.3.6</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-appendixB.html"><a href="B-appendixB.html#two-proportions"><i class="fa fa-check"></i><b>B.4</b> Two proportions</a><ul>
<li class="chapter" data-level="B.4.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-2"><i class="fa fa-check"></i><b>B.4.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.4.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-2"><i class="fa fa-check"></i><b>B.4.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.4.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-2"><i class="fa fa-check"></i><b>B.4.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.4.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-2"><i class="fa fa-check"></i><b>B.4.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.4.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-2"><i class="fa fa-check"></i><b>B.4.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.4.6" data-path="B-appendixB.html"><a href="B-appendixB.html#check-conditions-2"><i class="fa fa-check"></i><b>B.4.6</b> Check conditions</a></li>
<li class="chapter" data-level="B.4.7" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-2"><i class="fa fa-check"></i><b>B.4.7</b> Test statistic</a></li>
<li class="chapter" data-level="B.4.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-2"><i class="fa fa-check"></i><b>B.4.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.4.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-2"><i class="fa fa-check"></i><b>B.4.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-independent-samples"><i class="fa fa-check"></i><b>B.5</b> Two means (independent samples)</a><ul>
<li class="chapter" data-level="B.5.1" data-path="B-appendixB.html"><a href="B-appendixB.html#problem-statement-3"><i class="fa fa-check"></i><b>B.5.1</b> Problem statement</a></li>
<li class="chapter" data-level="B.5.2" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-3"><i class="fa fa-check"></i><b>B.5.2</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.5.3" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-3"><i class="fa fa-check"></i><b>B.5.3</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.5.4" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-3"><i class="fa fa-check"></i><b>B.5.4</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.5.5" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-3"><i class="fa fa-check"></i><b>B.5.5</b> Traditional methods</a></li>
<li class="chapter" data-level="B.5.6" data-path="B-appendixB.html"><a href="B-appendixB.html#test-statistic-3"><i class="fa fa-check"></i><b>B.5.6</b> Test statistic</a></li>
<li class="chapter" data-level="B.5.7" data-path="B-appendixB.html"><a href="B-appendixB.html#compute-p-value-1"><i class="fa fa-check"></i><b>B.5.7</b> Compute <span class="math inline">\(p\)</span>-value</a></li>
<li class="chapter" data-level="B.5.8" data-path="B-appendixB.html"><a href="B-appendixB.html#state-conclusion-3"><i class="fa fa-check"></i><b>B.5.8</b> State conclusion</a></li>
<li class="chapter" data-level="B.5.9" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-3"><i class="fa fa-check"></i><b>B.5.9</b> Comparing results</a></li>
</ul></li>
<li class="chapter" data-level="B.6" data-path="B-appendixB.html"><a href="B-appendixB.html#two-means-paired-samples"><i class="fa fa-check"></i><b>B.6</b> Two means (paired samples)</a><ul>
<li class="chapter" data-level="B.6.1" data-path="B-appendixB.html"><a href="B-appendixB.html#competing-hypotheses-4"><i class="fa fa-check"></i><b>B.6.1</b> Competing hypotheses</a></li>
<li class="chapter" data-level="B.6.2" data-path="B-appendixB.html"><a href="B-appendixB.html#exploring-the-sample-data-4"><i class="fa fa-check"></i><b>B.6.2</b> Exploring the sample data</a></li>
<li class="chapter" data-level="B.6.3" data-path="B-appendixB.html"><a href="B-appendixB.html#non-traditional-methods-4"><i class="fa fa-check"></i><b>B.6.3</b> Non-traditional methods</a></li>
<li class="chapter" data-level="B.6.4" data-path="B-appendixB.html"><a href="B-appendixB.html#traditional-methods-4"><i class="fa fa-check"></i><b>B.6.4</b> Traditional methods</a></li>
<li class="chapter" data-level="B.6.5" data-path="B-appendixB.html"><a href="B-appendixB.html#comparing-results-4"><i class="fa fa-check"></i><b>B.6.5</b> Comparing results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-appendixC.html"><a href="C-appendixC.html"><i class="fa fa-check"></i><b>C</b> Reach for the Stars</a><ul>
<li class="chapter" data-level="" data-path="C-appendixC.html"><a href="C-appendixC.html#needed-packages-11"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="C.1" data-path="C-appendixC.html"><a href="C-appendixC.html#sorted-barplots"><i class="fa fa-check"></i><b>C.1</b> Sorted barplots</a></li>
<li class="chapter" data-level="C.2" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-graphics"><i class="fa fa-check"></i><b>C.2</b> Interactive graphics</a><ul>
<li class="chapter" data-level="C.2.1" data-path="C-appendixC.html"><a href="C-appendixC.html#interactive-linegraphs"><i class="fa fa-check"></i><b>C.2.1</b> Interactive linegraphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-appendixD.html"><a href="D-appendixD.html"><i class="fa fa-check"></i><b>D</b> Learning Check Solutions</a><ul>
<li class="chapter" data-level="D.1" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-2-solutions"><i class="fa fa-check"></i><b>D.1</b> Chapter 2 Solutions</a></li>
<li class="chapter" data-level="D.2" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-3-solutions"><i class="fa fa-check"></i><b>D.2</b> Chapter 3 Solutions</a></li>
<li class="chapter" data-level="D.3" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-4-solutions"><i class="fa fa-check"></i><b>D.3</b> Chapter 4 Solutions</a></li>
<li class="chapter" data-level="D.4" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-5-solutions"><i class="fa fa-check"></i><b>D.4</b> Chapter 5 Solutions</a></li>
<li class="chapter" data-level="D.5" data-path="D-appendixD.html"><a href="D-appendixD.html#chapter-6-solutions"><i class="fa fa-check"></i><b>D.5</b> Chapter 6 Solutions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Inference via Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<html>
<img src='https://moderndive.com/wide_format.png' alt="ModernDive">
</html>
<div id="confidence-intervals" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Confidence Intervals</h1>
<hr />
<div class="announcement">
<p>
<strong>In preparation for our first print edition to be published by CRC Press in Fall 2019, we’re remodeling this chapter a bit. Don’t expect major changes in content, but rather only minor changes in presentation. Our remodeling will be complete and available online at <a href="https://moderndive.com/">ModernDive.com</a> by early Summer 2019!</strong>
</p>
</div>
<hr />
<p>In Chapter <a href="8-sampling.html#sampling">8</a>, we studied sampling. As an example we wanted to know the proportion of balls in the sampling bowl in Figure <a href="8-sampling.html#fig:sampling-exercise-1">8.1</a> that were red. While we could have performed an exhaustive count, this would have been a very tedious process. So instead we used a shovel to extract a sample of 50 balls. We then used the proportion of the shovel’s balls that were red as an estimate of the proportion of the bowl’s balls that are red. This sampling procedure was much less tedious than an exhuaustive count. Furthermore, we made sure to mix the bowl’s contents before using the shovel. However, because of the inherent randomness of the sampling induced by the mixing of the bowl, different shovel uses yielded different estimates of the proportion of the bowl’s balls that were red.</p>
<p>We then mimicked this “tactile” exercise with an equivalent “virtual” exercise done on the computer. Using our computers’ random number generator, we could very quickly repeat the above sampling procedure a large number of times. In Section <a href="8-sampling.html#different-shovels">8.2.4</a>, we quickly repeated the above sampling procedure 1000 times using three different “virtual” shovels, with 25, 50, and 1000 slots. We compared the variation of these three sets of 1000 estimates in the three histograms in Figure <a href="8-sampling.html#fig:comparing-sampling-distributions-3">8.13</a>.</p>
<p>What we did here was construct <strong>sampling distributions</strong>. The motivation for taking repeated samples and visualizing the resulting estimates was to understand the variability of our estimates from one sample to another; in other words the effect of <strong>sampling variation</strong>. We quantified the variation of our estimates via their standard deviation, which has a very special name: the <strong>standard error</strong>. In particular, we saw that as the sample size increased, the standard error decreased and the sampling distributions narrowed. In other words, larger samples lead to more <em>precise</em> estimates.</p>
<p>Let’s rephase the description of our sampling procedure using the terminology and mathematical notation related to sampling we introducted in Section <a href="8-sampling.html#terminology-and-notation">8.3.1</a>: Our <strong>study population</strong> was the large bowl with <span class="math inline">\(N\)</span> = 2400 balls, while the <strong>population parameter</strong> (the unknown quantity of interest) was the population proportion <span class="math inline">\(p\)</span> of the bowl’s balls that are red. Since performing a <strong>census</strong> was expensive in terms of time and energy, we extracted a <strong>sample</strong> of size <span class="math inline">\(n\)</span> = 50. The <strong>point estimate</strong> (AKA the <strong>sample statistic</strong>) used to estimate <span class="math inline">\(p\)</span> was the sample proportion <span class="math inline">\(\widehat{p}\)</span> of the 50 balls that were red. Futhermore, since the sample was obtained at <strong>random</strong>, it was <strong>representative</strong> of the population, and thus our estimate <span class="math inline">\(\widehat{p}\)</span> was <strong>unbiased</strong> and could be <strong>generalized</strong> to the population. In other words, the sample proportion <span class="math inline">\(\widehat{p}\)</span> of the shovel’s <span class="math inline">\(n\)</span> = 50 balls that were red was a “good guess” of the true population proportion <span class="math inline">\(p\)</span> of the bowl’s <span class="math inline">\(N\)</span> = 2400 balls that are red.</p>
<p>In particular, we emphasize that we used the point estimate/sample statistic, here the sample proportion <span class="math inline">\(\widehat{p}\)</span>, to estimate the unknown value of the population parameter, here the population proportion <span class="math inline">\(p\)</span>. In other words, we used the sample to <strong>infer</strong> about the population.</p>
<p>However, as we described in Section <a href="8-sampling.html#sampling-simulation">8.2</a>, both these tactile and virtual exercises were simulations used to study the effects of sampling variation and not real-life scenarios. In a real life situation, we would not take 1000 samples of size <span class="math inline">\(n\)</span>, but rather take <em>only one</em> sample that’s as large as possible. Additionally, in a real life scenario, we will not know what the true population proportion is like we did with our bowl. Because if we did, then why would we be estimating it via sampling? An example of a realistic sampling situation is the article on the <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">Obama poll</a> you saw in Section <a href="8-sampling.html#sampling-case-study">8.4</a> where pollsters wanted to know the proportion of all young Americans who supported President Obama based on a sample of size <span class="math inline">\(n\)</span> = 2089.</p>
<p>So what does one do in real life, when you only have <em>one</em> sample to work with? In other words, how can we comment on the effects of sampling variation when not in a simulation scenario? One common way is via a process known as <strong>bootstrapping resampling</strong>, which will be the focus of the earlier sections of this chapter. Furthermore, what if instead of a single estimate, we would like to give a <em>range of highly plausible</em> values of the unknown population parameter? Going back to the article, it stated that the pollsters’ estimate of the proportion of all young Americans who supported President Obama was 41%, but also that the poll’s “margin of error was plus or minus 2.1 percentage points.” In other words this “plausible range” was [41% - 2.1%, 41% + 2.1%] = [37.9%, 43.1%]. This range of plausible values is known as a <strong>confidence interval</strong> and will be the focus of the later sections.</p>
<div id="needed-packages-6" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Recall from our discussion in Section <a href="5-tidy.html#tidyverse-package">5.4.1</a> that loading the <code>tidyverse</code> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:</p>
<ul>
<li><code>ggplot2</code> for data visualization</li>
<li><code>dplyr</code> for data wrangling</li>
<li><code>tidyr</code> for converting data to “tidy” format</li>
<li><code>readr</code> for importing spreadsheet data into R</li>
<li>As well as the more advanced <code>purrr</code>, <code>tibble</code>, <code>stringr</code>, and <code>forcats</code> packages</li>
</ul>
<p>If needed, read Section <a href="2-getting-started.html#packages">2.3</a> for information on how to install and load R packages.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(moderndive)
<span class="kw">library</span>(infer)
<span class="kw">library</span>(janitor)</code></pre>
<hr />
</div>
<div id="resampling-activity" class="section level2">
<h2><span class="header-section-number">9.1</span> Resampling activity</h2>
<p>As we did in Chapter <a href="8-sampling.html#sampling">8</a>, we’ll begin with a hands-on activity.</p>
<div id="what-is-the-average-year-of-circulated-us-pennies-in-2019" class="section level3">
<h3><span class="header-section-number">9.1.1</span> What is the average year of circulated US pennies in 2019?</h3>
<p>In order to begin to answer this question, we obtained a sample of 50 US pennies collected from a bank in the US.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-a"></span>
<img src="images/sampling/pennies/bank.jpg" alt="Collecting a sample of 50 pennies." width="40%" /><img src="images/sampling/pennies/roll.jpg" alt="Collecting a sample of 50 pennies." width="40%" />
<p class="caption">
FIGURE 9.1: Collecting a sample of 50 pennies.
</p>
</div>
<p>An image of these pennies is below.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-256"></span>
<img src="images/sampling/pennies/pennies_trim.jpg" alt="50 US pennies" width="100%" />
<p class="caption">
FIGURE 9.2: 50 US pennies
</p>
</div>
<p>Each of the pennies was numbered as 1-50 starting in the top left and ending in the bottom right progressing row by row. This is shown with the “ID” values on top of and near the middle of each penny for clarity. The year of mint is also shown on top of and to the right side of the penny as well.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-257"></span>
<img src="images/sampling/pennies/labelled/01.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/02.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/03.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/04.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/05.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/06.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/07.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/08.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/09.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/10.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/11.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/12.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/13.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/14.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/15.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/16.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/17.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/18.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/19.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/20.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/21.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/22.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/23.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/24.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/25.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/26.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/27.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/28.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/29.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/30.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/31.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/32.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/33.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/34.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/35.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/36.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/37.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/38.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/39.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/40.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/41.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/42.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/43.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/44.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/45.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/46.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/47.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/48.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/49.jpg" alt="50 US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/50.jpg" alt="50 US pennies labelled" width="9%" />
<p class="caption">
FIGURE 9.3: 50 US pennies labelled
</p>
</div>
<p>The <code>moderndive</code> package contains this data on the pennies collected and minted in the United States in 2019. Let’s explore this sample data first:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample_<span class="dv">2</span></code></pre>
<pre><code># A tibble: 50 x 2
      ID  year
   &lt;int&gt; &lt;int&gt;
 1     1  2002
 2     2  1986
 3     3  2017
 4     4  1988
 5     5  2008
 6     6  1983
 7     7  2008
 8     8  1996
 9     9  2004
10    10  2000
# … with 40 more rows</code></pre>
<p>The <code>pennies_sample_2</code> data frame has rows corresponding to a single penny with two variables:</p>
<ul>
<li><code>ID</code> of the penny stored as an integer to identify the penny from other pennies in the sample and</li>
<li><code>year</code> of minting as shown on the penny and stored as an integer.</li>
</ul>
<p>Suppose we are interested in understanding some properties of the mean year of <strong>all</strong> US pennies using this data on 50 pennies collected in 2019. How might we go about that? Let’s begin by understanding some of the properties of <code>pennies_sample_2</code> using data visualization from Chapter <a href="3-viz.html#viz">3</a> and data wrangling from Chapter <a href="4-wrangling.html#wrangling">4</a>.</p>
<div id="exploratory-data-analysis-on-original-sample" class="section level4 unnumbered">
<h4>Exploratory data analysis on original sample</h4>
<p>First, let’s visualize the values in this sample as a histogram:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(pennies_sample_<span class="dv">2</span>, <span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-259-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>We see a skewed distribution here that has many values in the 1990s through 2010s with only a few older than 1970. If <code>pennies_sample_2</code> is a representative sample from the population, we’d expect the age of all US pennies collected in 2019 to have a similar shape, a similar spread, and similar measures of central tendency like the mean.</p>
<p>So where does the mean value fall for this sample? This point will be known as our <strong>point estimate</strong> and provides us with a single number that could serve as the guess to what the true population mean year might be. Recall how to find this using the <code>dplyr</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">x_bar &lt;-<span class="st"> </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))</code></pre>
<p>We’ve denoted this <em>sample mean</em> as <span class="math inline">\(\bar{x}\)</span>, which is the standard symbol for denoting the mean of a sample. Our point estimate is, thus, <span class="math inline">\(\bar{x} = 1995.44\)</span>. Note that this is just one sample though providing just one guess at the population mean. What if we’d like to have another guess?</p>
<p>This should all sound similar to what we did in Chapter <a href="8-sampling.html#sampling">8</a>. There instead of collecting just a single scoop of balls, we had many different students use the shovel to scoop different samples of red and white balls. We then calculated a sample statistic (the sample proportion) from each sample. But, we don’t have a population to pull from here with the pennies. We only have this one sample.</p>
<p>The process of <strong>resampling</strong> allows us to use a single sample to generate many different samples that will act as our way of approximating a sampling distribution. Let’s see how this works using our sample of fifty pennies.</p>
</div>
</div>
<div id="using-resampling-once" class="section level3">
<h3><span class="header-section-number">9.1.2</span> Using resampling once</h3>
<p>The fifty pennies represent one possible sample from all of the pennies in our population. As we saw in Chapter <a href="8-sampling.html#sampling">8</a>, there are other potential samples that could have been selected. All we know about the population is that it contains pennies with years equal to those in our sample. In our sample, we drew three pennies with a year of 1999. But will we always draw exactly three pennies with a year of 1999 if we drew other samples of size 50? More than likely not. We might draw 0, 1, 2, or even all 50 pennies as being from 1999. The same can be said for the other 26 years that are represented in our sample.</p>
<p>Taking our sample of fifty pennies, we can perform a resampling process to obtain another potential sample from the population. This will help us get a sense for the variability in another sample like what we did in Chapter <a href="8-sampling.html#sampling">8</a>. Here’s the process:</p>
<ol style="list-style-type: decimal">
<li>First, pretend that each of the 50 values of <code>year</code> in <code>pennies_sample_2</code> was written on a small piece of paper. Recall that these values were 2002, 1986, 2017, 1988, 2008, etc. We also note the <code>ID</code> values here on each sheet of paper of 1, 2, 3, 4, 5, etc. to keep track of how resampling works.</li>
<li>Now, put the 50 small pieces of paper into a receptacle such as a baseball cap.</li>
<li>Shake up the pieces of paper.</li>
<li>Draw “at random” from the cap to select one piece of paper.</li>
<li>Write down the value of <code>age</code> and <code>ID</code> on this piece of paper. Say that it is 1976 for <code>year</code> and 32 for <code>ID</code>.</li>
<li>Now, place this piece of paper corresponding to the 32nd coin with a value of 1976 back into the cap.</li>
<li>Draw “at random” again from the cap to select a piece of paper. Note that this is the <em>sampling with replacement</em> part since you may draw this 39th coin again.</li>
<li>Repeat this process until you have drawn 50 pieces of paper and written down the <code>ID</code> and <code>year</code> values for these 50 pieces of paper. Completing this repetition produces ONE resample.</li>
</ol>
<p>Let’s enter these values into R in a tibble called <code>pennies_resample</code> and observe the first ten rows of this resample.</p>
<!-- Add `pennies_resample` to moderndive -->
<pre><code># A tibble: 50 x 2
      ID  year
   &lt;int&gt; &lt;int&gt;
 1    32  1976
 2    37  1962
 3    22  1976
 4     6  1983
 5    24  2017
 6    39  2015
 7    16  2015
 8    37  1962
 9    17  2016
10    32  1976
# … with 40 more rows</code></pre>
<p>Now we can view what the actual pennies sampled would look like corresponding to this resample:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-262"></span>
<img src="images/sampling/pennies/labelled/32.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/37.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/22.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/06.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/24.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/39.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/16.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/37.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/17.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/32.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/28.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/45.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/48.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/44.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/16.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/29.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/17.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/14.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/26.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/42.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/15.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/31.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/30.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/44.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/07.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/47.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/02.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/25.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/21.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/09.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/10.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/12.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/38.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/49.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/25.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/36.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/25.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/23.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/21.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/16.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/10.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/38.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/29.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/46.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/41.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/45.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/40.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/29.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/28.jpg" alt="50 resampled US pennies labelled" width="9%" /><img src="images/sampling/pennies/labelled/10.jpg" alt="50 resampled US pennies labelled" width="9%" />
<p class="caption">
FIGURE 9.4: 50 resampled US pennies labelled
</p>
</div>
<p>Note the different <code>ID</code> values and <code>year</code> values for each penny here. There are also some pennies drawn multiple times and some pennies not drawn at all from our original sample.</p>
<div id="exploratory-data-analysis-on-the-resample" class="section level4 unnumbered">
<h4>Exploratory data analysis on the resample</h4>
<p>Let’s look at the distribution of <code>year</code>s in the original sample of <code>pennies_sample_2</code> compared to the resample of <code>pennies_resample</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(pennies_sample_<span class="dv">2</span>, <span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;50 US pennies labelled&quot;</span>)
<span class="kw">ggplot</span>(pennies_resample, <span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;50 resampled US pennies labelled&quot;</span>)</code></pre>

<div class="figure" style="text-align: center"><span id="fig:orig-and-resample"></span>
<img src="ismaykim_files/figure-html/orig-and-resample-1.png" alt="Comparing years of original sample pennies_sample_2 and resample pennies_resample" width="\textwidth" />
<p class="caption">
FIGURE 9.5: Comparing years of original sample <code>pennies_sample_2</code> and resample <code>pennies_resample</code>
</p>
</div>
<p>Note the similarities and differences between these two distributions. The general shape of the two distributions is similar. This won’t always be the case for all resamples since there is some chance that values that don’t appear frequently in the original sample won’t be drawn in the resample. Note also that the range of possible values taken on for the years is the same as what was seen in <code>pennies_sample_2</code>. In other words, we don’t see any years such as 1948 or 1952 in the <code>pennies_resample</code> data. This will always be the case with resamples since they are, by their name, sampling again from the original sample.</p>
<p>So where does the mean of the <code>year</code> variable for this resample of <code>pennies_resample</code> fall? Any guesses? Let’s have <code>dplyr</code> help us out here:</p>
<pre class="sourceCode r"><code class="sourceCode r">resample_mean &lt;-<span class="st"> </span>pennies_resample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))</code></pre>
<p>The value of the resampled mean is 1994.82. We might have guessed that our mean here is similar to what we saw for the mean of <code>pennies_sample_2</code> of 1995.44 based on the distributions in the histogram in Figure <a href="9-confidence-intervals.html#fig:orig-and-resample">9.5</a>.</p>
<p>What if we repeated several times this exercise of resampling 50 times from our sample of pennies? Would we obtain the same mean <code>year</code> value each time? In other words, would our guess at the mean year of all pennies in the US in 2019 be exactly 1994.82 every time? This should remind you of what we did in Chapter <a href="8-sampling.html#sampling">8</a>. Let’s do some more resamplings and observe the results with the help of 33 friends again.</p>
</div>
</div>
<div id="student-resamples" class="section level3">
<h3><span class="header-section-number">9.1.3</span> Using resampling 33 times</h3>
<p>Each of our 33 friends will do the following:</p>
<ol style="list-style-type: decimal">
<li>Each takes 50 sheets of paper that show the different <code>ID</code> and <code>year</code> pairings from the <code>pennies_sample_2</code> original sample.</li>
<li>Then, each puts the 50 small pieces of paper into something like a baseball cap.</li>
<li>Shake up the pieces of paper.</li>
<li>Draw “at random” from the cap to select one piece of paper.</li>
<li>Write down the value of <code>age</code> and <code>ID</code> on this piece of paper.</li>
<li>Next, place this piece of paper just drawn back into the cap to have 50 small pieces of paper again.</li>
<li>Draw “at random” again from the cap to select a piece of paper.</li>
<li>Repeat this process until each of your friends have drawn 50 pieces of paper and each has written down the <code>ID</code> and <code>year</code> values for these 50 pieces of paper.</li>
</ol>
<p>Now each of your 33 friends has a resample of penny <code>ID</code> and <code>year</code> pairings. You now ask your friends to each compute the mean of the <code>year</code> values for each of their resamples. Using a similar strategy to what was done in Chapter <a href="8-sampling.html#sampling">8</a>, we build out our histogram manually:</p>
<!-- Need to insert a histogram here "drawn" with Post-It notes. Showing
the actual ggplot2 for reference here. -->
<!-- Albert will update with actual values here taken from his class for the next go-round of the book. -->
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise"></span>
<img src="ismaykim_files/figure-html/resampling-exercise-1.png" alt="Constructing a histogram of means from resamples." width="\textwidth" />
<p class="caption">
FIGURE 9.6: Constructing a histogram of means from resamples.
</p>
</div>
<p>Observe the following about the histogram in Figure <a href="9-confidence-intervals.html#fig:resampling-exercise">9.6</a>:</p>
<!-- Will need to update this with the actual values of the in-class activity -->
<ul>
<li>Only one of your friends has a mean year between 1991 and 1992.</li>
<li>On the other side of the distribution, only one of your friends has a mean year between 1999 and 2000.</li>
<li>The most frequently occurring range is between 1995 and 1996 with 8 entries, but 1992 to 1993, 1993 to 1994, and 1996 to 1997 each have 6 entries.</li>
<li>The distribution is starting to show a bit of normality, but that might be a stretch to guess at with this small of a sample size.</li>
</ul>
<p>The different mean values reported by your 33 friends are stored in the <code>tactile_sample_means</code> tibble shown below.</p>
<pre class="sourceCode r"><code class="sourceCode r">tactile_resample_means
<span class="kw">View</span>(tactile_resample_means)</code></pre>
<p>Let’s display only the first 10 out of 33 rows of <code>tactile_resample_means</code>’s contents in Table <a href="#tab:tactile-resample-means"><strong>??</strong></a>.</p>


<p>Recall the <code>replicate</code> column here similar to the one shown in Chapter <a href="8-sampling.html#sampling">8</a> enumerating each of the 33 groups. This again corresponds to each row being viewed as one instance of a replicated activity. The activity here is the sampling with replacement from the original sample 50 times to create a resample.</p>
<p>The distribution of the 33 means of these resamples is given using <code>geom_histogram()</code> with <code>binwidth = 1</code> in Figure <a href="9-confidence-intervals.html#fig:resamplingdistribution-tactile">9.7</a>. As with the similar plot from Chapter <a href="8-sampling.html#sampling">8</a> for the proportion of red balls, this computer-generated histogram matches our hand-drawn histogram from the earlier Figure <a href="9-confidence-intervals.html#fig:resampling-exercise">9.6</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(tactile_resample_means, <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> stat)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">boundary =</span> <span class="dv">1990</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1990</span>, <span class="dv">2000</span>, <span class="dv">2</span>))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:resamplingdistribution-tactile"></span>
<img src="ismaykim_files/figure-html/resamplingdistribution-tactile-1.png" alt="Distribution of 33 means based on 33 resamples of size 50" width="\textwidth" />
<p class="caption">
FIGURE 9.7: Distribution of 33 means based on 33 resamples of size 50
</p>
</div>
</div>
<div id="whats-the-plan" class="section level3">
<h3><span class="header-section-number">9.1.4</span> What’s the plan?</h3>
<p>We’ve just gone over how to use the technique of <em>resampling</em> to make a guess as to what the variability would look like if we were to take samples from a population. Thus, in essence, the <em>resampling distribution</em> would be an approximation of the <em>sampling distribution</em> discussed in Chapter <a href="8-sampling.html#sampling">8</a>. We saw that we obtained many different means from these resamples and began to see the underpinnings of the normal distribution take shape in the first 33 resamples made by our friends.</p>
<p>In Section <a href="9-confidence-intervals.html#resampling-simulation">9.2</a> we’ll use <em>computer simulation</em> to imitate the hands-on resampling activity conducted here. We can use a computer to do the resampling many more times than just having our friends do this for us. This will allow us to better understand the distribution of means from many different resamples. Following these simulations, in Section <a href="9-confidence-intervals.html#ci-build-up">9.3</a> we’ll explicitly articulate our goals for this chapter: understanding the concept of resampling variation, defining the statistical idea of a <em>confidence interval</em> by building on our pennies example, and discussing how confidence intervals can be interpreted.</p>
<p>Following this framework on confidence intervals, we’ll discuss the <code>dplyr</code> and <code>infer</code> package code needed to complete the process of <em>bootstrapping</em>, which is another name for this resampling approach that is most commonly found in developing confidence intervals. We’ve used one of the functions in the <code>infer</code> package already with <code>rep_sample_n()</code>, but there’s a lot more to this package than just that. We’ll introduce the tidy statistical inference framework that was the motivation for the <code>infer</code> package pipeline that will be the driving package throughout the rest of this book.</p>
<p>As we did in Chapter <a href="8-sampling.html#sampling">8</a>, we’ll tie these ideas together with a case study in Section <a href="9-confidence-intervals.html#case-study-two-prop-ci">9.7</a>. Here we will be analyzing an experiment done about yawning on the US television show Mythbusters. The chapter concludes with a comparison of a sampling distribution and a bootstrap distribution using the balls data from Chapter <a href="8-sampling.html#sampling">8</a>. We’ll also discuss briefly the normal distribution and how these traditionally taught theoretical results tie in with the methods developed throughout the chapter.</p>
</div>
</div>
<div id="resampling-simulation" class="section level2">
<h2><span class="header-section-number">9.2</span> Computer simulation of resampling</h2>
<p>We’ve completed a tactile example of resampling. We’ll next explore how this can be done virtually using the computer.</p>
<div id="using-the-virtual-resample-once" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Using the virtual resample once</h3>
<p>Recall that <code>pennies_sample_2</code> is stored as a dataset in the <code>moderndive</code> package. We’ve used the <code>rep_sample_n()</code> function in Chapter <a href="8-sampling.html#sampling">8</a> to take samples from a population using <code>replace = FALSE</code> as the default. If we change this to <code>replace = TRUE</code>, we can also use this function to resample from a given original sample. Let’s try this out:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resample &lt;-<span class="st"> </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1</span>)</code></pre>
<p>Note here that the <code>size</code> argument should always be the same as the original sample size. We are doing this resampling one time and, thus, <code>reps = 1</code>. So what does <code>virtual_resample</code> look like?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">View</span>(virtual_resample)</code></pre>
<p>We’ll display only the first 10 out of 50 rows of <code>virtual_shovel</code>’s contents in Table <a href="#tab:virtual-shovel"><strong>??</strong></a>.</p>

<p>The <code>ID</code> variable identifies which of the pennies from <code>pennies_sample_2</code> are included in our resample of 50 coins and <code>year</code> denotes the year minted on the penny. The <code>replicate</code> column here is always the value of 1 corresponding to us only having <code>reps = 1</code>. It will take values between 1 and 33 next. But before we get to resampling multiple times, let’s compute the mean <code>year</code> in our virtual resample of size 50 using <code>dplyr</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">resample_mean =</span> <span class="kw">mean</span>(year))</code></pre>
<pre><code># A tibble: 1 x 2
  replicate resample_mean
      &lt;int&gt;         &lt;dbl&gt;
1         1       1995.48</code></pre>
<!-- Not sure if needed, but those trying to follow along may be mystified
if we don't include this. -->
<p>Note that tibbles will try to print as pretty as possible which may result in numbers being rounded. In this chapter, we have set the default number of values to be printed to six in tibbles with <code>options(pillar.sigfig = 6)</code>.</p>
</div>
<div id="using-the-virtual-resample-33-times" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Using the virtual resample 33 times</h3>
<p>Let’s now extend this to have 33 virtual friends help us understand the variability in the means from 33 resamples of size 50.</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resamples &lt;-<span class="st"> </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">33</span>)
<span class="kw">View</span>(virtual_resamples)</code></pre>
<p>Just as we did with <code>virtual_resample</code>, we’ll take the tibble <code>virtual_resamples</code> with 33 <span class="math inline">\(\times\)</span> 50 = 1650 rows corresponding to 33 resamples of size 50 pennies and then compute the resulting 33 means. We’ll use the same <code>dplyr</code> verb as we did in the previous section, but compute the mean for each of our virtual friends:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resample_means &lt;-<span class="st"> </span>virtual_resamples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))
<span class="kw">View</span>(virtual_resample_means)</code></pre>


<p>By looking at these first 10 rows, we can see values in the same range as those obtained from our friends’ resamples in Table <a href="#tab:tactile-resample-means"><strong>??</strong></a>. Let’s next visualize these 33 means:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(virtual_resample_means, <span class="kw">aes</span>(<span class="dt">x =</span> stat)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">boundary =</span> <span class="dv">1990</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">1990</span>, <span class="dv">2000</span>, <span class="dv">2</span>))</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-274-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>Let’s next compare the two distributions of the tactile resampling done by friends and the virtual resampling done by the computer:</p>
<div class="figure" style="text-align: center"><span id="fig:orig-and-resample-means"></span>
<img src="ismaykim_files/figure-html/orig-and-resample-means-1.png" alt="Comparing distributions of means from resamples`" width="\textwidth" />
<p class="caption">
FIGURE 9.8: Comparing distributions of means from resamples`
</p>
</div>
<!-- Good learning check here would be for learners to compare the distributions since we did something similar in Chapter 8 and they should be well versed on this by now. -->
</div>
<div id="using-the-virtual-resample-1000-times" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Using the virtual resample 1000 times</h3>
<p>Remember that one of the goal of resampling is to get an estimate for what the sampling distribution of the statistic of interest, the mean year here, looks like. To do so we’ll need lots of different replicates to better understand the shape and the variability from one resample to the next. Let’s extend our 33 replicates above to look at 1000 instead. With our goal being to get to 1000 resample means, we can use the <code>%&gt;%</code> to get us there in one chain:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resample_means &lt;-<span class="st"> </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))</code></pre>
<p>Let’s next look at what this distribution of 1000 sample means from 1000 resamples looks like in Figure <a href="9-confidence-intervals.html#fig:one-thousand-sample-means">9.9</a>:</p>
<div class="figure" style="text-align: center"><span id="fig:one-thousand-sample-means"></span>
<img src="ismaykim_files/figure-html/one-thousand-sample-means-1.png" alt="Bootstrap resampling distribution based on 1000 resamples." width="\textwidth" />
<p class="caption">
FIGURE 9.9: Bootstrap resampling distribution based on 1000 resamples.
</p>
</div>
<p>Note here the bell shape starting to become more apparent. We now have a general sense for the range of values that the mean may take on in these resamples from this histogram. Do you have a guess as to where this histogram is centered? With it being close to symmetric, either the mean or the median would serve as a good estimate for the center here. Let’s look at the mean:</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_resample_means <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_of_means =</span> <span class="kw">mean</span>(stat))</code></pre>
<p>The mean of the 1000 means from 1000 resamples is 1995.441. Note that this is quite close to the mean of our original sample: 1995.44. This will always be the case when we have 1000 or so replicates since each of the resamples is based on the original sample.</p>
<!-- Another good learning check here would be to ask learners to summarize important features of the plot as was done in Chapter 8. -->
</div>
</div>
<div id="ci-build-up" class="section level2">
<h2><span class="header-section-number">9.3</span> Confidence interval build-up</h2>
<p><strong>Definition: Confidence Interval</strong></p>
<p>A <em>confidence interval</em> (CI) gives a range of plausible values for a parameter. It depends on a specified <em>confidence level</em> with higher confidence levels corresponding to wider confidence intervals and lower confidence levels corresponding to narrower confidence intervals. Common confidence levels include 90%, 95%, and 99%.</p>
<p>Usually, we don’t just begin sections with a definition, but <em>confidence intervals</em> are simple to define and play an important role in the sciences and any field that uses data. We’ve also just shown the build-up to them visually in the previous section.</p>
<p>You can think of a confidence interval as playing the role of a net when fishing. Instead of just trying to catch a fish with a single spear (estimating an unknown parameter by using a single point estimate/sample statistic), we can use a net to try to provide a range of possible locations for the fish (use a range of possible values based around our statistic to make a plausible guess as to the location of the parameter).</p>
<table>
<thead>
<tr class="header">
<th align="center">Point estimate/sample statistic</th>
<th align="center">Confidence interval</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><img src="images/spear.jpg" style="height:1.7in" /></td>
<td align="center"><img src="images/net2.jpg" style="height:1.7in" /></td>
</tr>
</tbody>
</table>
<p>The resampling process will provide statistics that have a distribution with center at (or extremely close to) the mean of the original sample. The distribution of statistics brought forth by resampling, also called the <em>resampling distribution</em> provides us a guess as to what the variability in different sample means may look like only using the original sample as our guide. We can quantify this variability in the form of a 95% confidence interval in a couple of different ways.</p>
<div id="percentile-method" class="section level3">
<h3><span class="header-section-number">9.3.1</span> The percentile method</h3>
<p>Recall that the actual mean year for all pennies in circulation in the US is unknown to us. But by finding a confidence interval we have a way to make an educated guess as to what a range of plausible values is for the unknown parameter. One way to calculate this range is to use the middle 95% of the <code>virtual_resample_means</code> to determine our endpoints. Our endpoints are thus at the 2.5<sup>th</sup> and 97.5<sup>th</sup> percentiles. We can visualize these percentiles on our distribution with green vertical lines:</p>
<!--
This can be done with `infer` using the `get_ci()` function. (You can also use the `conf_int()` or `get_confidence_interval()` functions here as they are aliases that work the exact same way.)
-->
<p><img src="ismaykim_files/figure-html/unnamed-chunk-278-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>Using the percentile method, our range of plausible values for the mean age of US pennies in circulation in 2011 is 1991.339 years to 1999.401 years. You’ll see in later sections how to compute these values.</p>
<p>You can see that 95% of the data stored in the <code>stat</code> variable in <code>virtual_resample_means</code> falls between the two endpoints with 2.5% to the left outside of the shading and 2.5% to the right outside of the shading. The cut-off points that provide our range are shown with the green lines.</p>
</div>
<div id="the-standard-error-method" class="section level3">
<h3><span class="header-section-number">9.3.2</span> The standard error method</h3>
<p>If the resampling distribution is close to symmetric and bell-shaped, we can also use a shortcut formula for determining the lower and upper endpoints of the confidence interval. This is done by using the formula <span class="math inline">\(\bar{x} \pm (multiplier * SE),\)</span> where <span class="math inline">\(\bar{x}\)</span> is our original sample mean and <span class="math inline">\(SE\)</span> stands for <strong>standard error</strong> and corresponds to the standard deviation of the resampling distribution. The value of <span class="math inline">\(multiplier\)</span> here is the appropriate percentile of the standard normal distribution. We’ll go into this further in Section <a href="9-confidence-intervals.html#ci-conclusion">9.8</a>.</p>
<!--
These are automatically calculated when `level` is provided with `level = 0.95` being the default. (95% of the values in a standard normal distribution fall within 1.96 standard deviations of the mean, so $multiplier = 1.96$ for `level = 0.95`, for example.)  As mentioned, this formula assumes that the bootstrap distribution is symmetric and bell-shaped. This is often the case with bootstrap distributions, especially those in which the original distribution of the sample is not highly skewed.
-->
<p><strong>Definition: standard error</strong></p>
<p>The <em>standard error</em> is the standard deviation of the sampling distribution.</p>
<p>The variability of the sampling distribution may be approximated by the variability of the resampling distribution. Traditional theory-based methodologies for inference also have formulas for standard errors, assuming some conditions are met.</p>
<p>Let’s next see how the lower and upper values of the confidence interval compare across the two methods of “percentile” and “standard error.”</p>
<!--
This $\bar{x} \pm (multiplier * SE)$ formula is implemented in the `get_ci()` function as shown with our pennies problem using the bootstrap distribution's variability as an approximation for the sampling distribution's variability. We'll see more on this approximation shortly.

Note that the center of the confidence interval (the `point_estimate`) must be provided for the standard error confidence interval.



```r
standard_error_ci <- bootstrap_distribution %>% 
  get_ci(type = "se", point_estimate = x_bar)
standard_error_ci
```
-->
<p><img src="ismaykim_files/figure-html/unnamed-chunk-280-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>We see that both methods produce nearly identical confidence intervals with the percentile method being <span class="math inline">\([1991.34, 1999.4]\)</span> and the standard error method being <span class="math inline">\([1991.28, 1999.6]\)</span>. This is to be expected since the resampling distribution is roughly bell-shaped. Now that you’ve seen how these methods work, let’s dig into the formalities of the process and the code needed to calculate them.</p>
<hr />
</div>
</div>
<div id="bootstrap-process" class="section level2">
<h2><span class="header-section-number">9.4</span> The bootstrapping framework</h2>
<p>The way in which we used resamples to get a range of plausible for an unknown parameter is known as <strong>bootstrapping.</strong> To better understand this term, we harken back to the idea of pulling oneself up by their bootstraps. To “pull oneself up by their bootstraps” means to <a href="https://en.wiktionary.org/wiki/pull_oneself_up_by_one%27s_bootstraps">“succeed only by one’s own efforts or abilities.”</a> From a statistical perspective, we have pulled ourselves up from our bootstraps using a single sample (<code>pennies_sample_2</code>) to get an idea of the grander sampling distribution. Thus, we’ve used only the “effort” of the single original sample to approximate a larger goal of the variability in the sampling distribution.</p>
<p>Bootstrapping uses a process of sampling <strong>with replacement</strong> from our original sample to create new <strong>bootstrap samples</strong> of the <em>same</em> size as our original sample. We can again make use of the <code>rep_sample_n()</code> function to explore what one such bootstrap sample would look like. Remember that we are randomly sampling from the original sample here with replacement and that we always use the same sample size for the bootstrap samples as the size of the original sample (<code>pennies_sample_2</code>).</p>
<div id="the-original-workflow-needed-for-this" class="section level3">
<h3><span class="header-section-number">9.4.1</span> The original workflow needed for this</h3>
<p>We saw earlier in Section <a href="9-confidence-intervals.html#resampling-simulation">9.2</a> how to develop these bootstrap samples, bootstrap statistics, and the resulting <em>bootstrap distribution</em>. We called this <em>bootstrap distribution</em> the <em>resampling distribution</em> before to drill home the idea of this being based on resampling (sampling with replacement) instead of sampling without replacement as seen in Chapter <a href="8-sampling.html#sampling">8</a>. Let’s revisit the flow using the <code>%&gt;%</code> but this time call it <code>bootstrap_distribution</code>.</p>
<p>First, we repeatedly (<code>reps = 1000</code>) sampled with replacement (<code>replace = TRUE</code>) from the original sample with the same size of the resample (<code>size = 50</code>) using the <code>rep_sample_n()</code> function in the <code>infer</code> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</code></pre>
<p>Next, since we are looking to get the mean value for year across each <code>replicate</code>, we used the <code>dplyr</code> verb <code>group_by()</code> to set up that grouping for our next step:</p>
<pre class="sourceCode r"><code class="sourceCode r"> pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) </code></pre>
<p>Lastly, we finish off the grouping by using <code>summarize()</code> from <code>dplyr</code> to get our mean value for year from each <code>replicate</code>. We also name this resulting 1000 row data frame <code>bootstrap_distribution</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"> bootstrap_distribution &lt;-<span class="st"> </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))</code></pre>
<p>So for the case where we are bootstrapping a single variable like <code>year</code> that we have seen so far, we can get by with using the <code>rep_sample_n()</code> function and a couple <code>dplyr</code> verbs to get the bootstrap distribution. For more complicated inferential techniques we need a little more firepower though. Let’s check out the <code>infer</code> package for tidy statistical inference!</p>
</div>
<div id="the-infer-package-for-statistical-inference" class="section level3">
<h3><span class="header-section-number">9.4.2</span> The infer package for statistical inference</h3>
<p>The <code>infer</code> package makes great use of the <code>%&gt;%</code> to create a pipeline for statistical inference. The goal of the package is to provide a way for its users to explain the computational process of confidence intervals and hypothesis tests using the code as a guide. The verbs build in order here, so you’ll want to start with <code>specify()</code> and then continue through the others as needed.</p>
<div id="specify-variables" class="section level4 unnumbered">
<h4>Specify variables</h4>
<p><img src="images/flowcharts/infer/specify.png" width="30%" style="display: block; margin: auto;" /></p>
<p>The <code>specify()</code> function is used primarily to choose which variables will be the focus of the statistical inference. In addition, a setting of which variable will act as the <code>explanatory</code> and which acts as the <code>response</code> variable is done here. For proportion problems similar to those in Chapter <a href="8-sampling.html#sampling">8</a>, we can also give which of the different levels we would like to have as a <code>success</code>. We’ll see further examples of these options in this chapter, Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>, and in Appendix <a href="B-appendixB.html#appendixB">B</a>.</p>
<p>To begin to create a confidence interval for the population mean year of US pennies in 2019, we start by using <code>specify()</code> to choose which variable in our <code>pennies_sample_2</code> data we’d like to work with. This can be done in one of two ways:</p>
<ol style="list-style-type: decimal">
<li>Using the <code>response</code> argument:</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year)</code></pre>
<pre><code>Response: year (integer)
# A tibble: 50 x 1
    year
   &lt;int&gt;
 1  2002
 2  1986
 3  2017
 4  1988
 5  2008
 6  1983
 7  2008
 8  1996
 9  2004
10  2000
# … with 40 more rows</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Using <code>formula</code> notation:</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> year <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>)</code></pre>
<pre><code>Response: year (integer)
# A tibble: 50 x 1
    year
   &lt;int&gt;
 1  2002
 2  1986
 3  2017
 4  1988
 5  2008
 6  1983
 7  2008
 8  1996
 9  2004
10  2000
# … with 40 more rows</code></pre>
<p>Note that the formula notation uses the common R methodology to include the response <span class="math inline">\(y\)</span> variable on the left of the <code>~</code> and the explanatory <span class="math inline">\(x\)</span> variable on the right of the “tilde.” Recall that you used this notation frequently with the <code>lm()</code> function in Chapters <a href="6-regression.html#regression">6</a> and <a href="7-multiple-regression.html#multiple-regression">7</a> when fitting regression models. Either notation works just fine, but preference is usually given here for the <code>formula</code> notation to further build on the ideas from earlier chapters.</p>
</div>
<div id="generate-replicates" class="section level4 unnumbered">
<h4>Generate replicates</h4>
<p><img src="images/flowcharts/infer/generate.png" width="70%" style="display: block; margin: auto;" /></p>
<p>After <code>specify()</code>ing the variables we’d like in our inferential analysis, we next feed that into the <code>generate()</code> verb. The <code>generate()</code> verb’s main argument is <code>reps</code>, which is used to give how many different repetitions one would like to perform. Another argument here is <code>type</code>, which is automatically determined by the kinds of variables passed into <code>specify()</code>. We can also be explicit and set this <code>type</code> to be <code>type = &quot;bootstrap&quot;</code>. If you are not explicit, <code>infer</code> will send you a message just to make sure this is what you are wanting. This <code>type</code> argument will be further used in hypothesis testing in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a> as well. Make sure to check out <code>?generate</code> to see the options here and use the <code>?</code> operator to better understand other verbs as well.</p>
<p>Let’s <code>generate()</code> 1000 bootstrap samples:</p>
<pre class="sourceCode r"><code class="sourceCode r">thousand_bootstrap_samples &lt;-<span class="st"> </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</code></pre>
<p>We can use the <code>dplyr</code> <code>count()</code> function to help us understand what the <code>thousand_bootstrap_samples</code> data frame looks like:</p>
<pre class="sourceCode r"><code class="sourceCode r">thousand_bootstrap_samples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(replicate)</code></pre>
<pre><code># A tibble: 1,000 x 2
# Groups:   replicate [1,000]
   replicate     n
       &lt;int&gt; &lt;int&gt;
 1         1    50
 2         2    50
 3         3    50
 4         4    50
 5         5    50
 6         6    50
 7         7    50
 8         8    50
 9         9    50
10        10    50
# … with 990 more rows</code></pre>
<p>Notice that each <code>replicate</code> has 50 entries here. Now that we have 1000 different bootstrap samples, our next step is to <code>calculate</code> the bootstrap statistics for each sample.</p>
<p><strong>Comparing back to original workflow</strong></p>
<p>Note that the steps up to this point of the <code>infer</code> pipeline produce the same procedure as what we saw before with <code>rep_sample_n()</code>. In other words, the following two code chunks produce similar results:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># With infer pipeline             # Without infer pipeline</span>
pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st">              </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st">      </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, 
   <span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>)                         <span class="dt">replace =</span> <span class="ot">TRUE</span>, 
                                                 <span class="dt">reps =</span> <span class="dv">1000</span>)</code></pre>
</div>
<div id="calculate-summary-statistics" class="section level4 unnumbered">
<h4>Calculate summary statistics</h4>
<p><img src="images/flowcharts/infer/calculate.png" width="70%" style="display: block; margin: auto;" /></p>
<p>After <code>generate()</code>ing many different samples, we next want to condense those samples down into a single statistic for each <code>replicate</code>d sample. As seen in the diagram, the <code>calculate()</code> function is helpful here.</p>
<p>As we did at the beginning of this chapter, we now want to calculate the mean <code>year</code> for each bootstrap sample. To do so, we use the <code>stat</code> argument and set it to <code>&quot;mean&quot;</code> below. The <code>stat</code> argument has a variety of different options here and we will see further examples of this throughout the remaining chapters.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution &lt;-<span class="st"> </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;mean&quot;</span>)</code></pre>
<pre><code>Setting `type = &quot;bootstrap&quot;` in `generate()`.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution</code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate    stat
       &lt;int&gt;   &lt;dbl&gt;
 1         1 1997.42
 2         2 1996.1 
 3         3 1995.64
 4         4 1994.78
 5         5 1994.46
 6         6 1995.42
 7         7 1995.98
 8         8 1992.18
 9         9 1993.06
10        10 1992.22
# … with 990 more rows</code></pre>
<p>We see that the resulting data has 1000 rows and 2 columns corresponding to the 1000 replicates and the mean for each bootstrap sample.</p>
<p><strong>Comparing back to original workflow</strong></p>
<p>We can see that the <code>calculate()</code> step does what the <code>group_by() %&gt;% summarize()</code> steps do in the original workflow:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># With infer pipeline             # Without infer pipeline</span>
pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st">              </span>pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st">      </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, 
  <span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st">                      </span><span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;mean&quot;</span>)          <span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                                    </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))</code></pre>
</div>
<div id="observed-statistic-point-estimate-calculations" class="section level4 unnumbered">
<h4>Observed statistic / point estimate calculations</h4>
<p>Just as <code>group_by() %&gt;% summarize()</code> produces a useful workflow in <code>dplyr</code>, we can also use <code>specify() %&gt;% calculate()</code> to compute summary measures on our original sample data. It’s often helpful both in confidence interval calculations, but also in hypothesis testing to identify what the corresponding statistic is in the original data. For our example on penny age, we computed above a value of <code>x_bar</code> using the <code>summarize()</code> verb in <code>dplyr</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(year))</code></pre>
<pre><code># A tibble: 1 x 1
     stat
    &lt;dbl&gt;
1 1995.44</code></pre>
<p>This can also be done by skipping the <code>generate()</code> step in the pipeline feeding <code>specify()</code> directly into <code>calculate()</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">pennies_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">response =</span> year) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;mean&quot;</span>)</code></pre>
<pre><code># A tibble: 1 x 1
     stat
    &lt;dbl&gt;
1 1995.44</code></pre>
<p>This shortcut will be particularly useful when the calculation of the observed statistic is tricky to do using <code>dplyr</code> alone. This is particularly the case when working with more than one variable as will be seen in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>.</p>
</div>
<div id="visualize-the-results" class="section level4 unnumbered">
<h4>Visualize the results</h4>
<p><img src="images/flowcharts/infer/visualize.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>The <code>visualize()</code> verb provides a simple way to view the bootstrap distribution as a histogram of the <code>stat</code> variable values. It has many other arguments that one can use as well including the shading of the histogram values corresponding to the confidence interval values.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">visualize</span>()
<span class="co"># or</span>
<span class="kw">visualize</span>(bootstrap_distribution)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-299-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>The shape of this resulting distribution may look familiar to you. It resembles the well-known normal (bell-shaped) curve.</p>
<p>The following diagram recaps the <code>infer</code> pipeline for creating a bootstrap distribution.</p>
<p><img src="images/flowcharts/infer/ci_diagram.png" width="\textwidth" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="infer-ci" class="section level3">
<h3><span class="header-section-number">9.4.3</span> Building confidence intervals with the infer package</h3>
<p>Recall how we showed two different methods for building a range of plausible values for an unknown parameter in Section <a href="9-confidence-intervals.html#confidence-intervals">9</a>. Let’s now check out how the <code>infer</code> package and some new functions were used to get us there. There’s also some additional functionality to further assist with visualizing the intervals built-in!</p>
</div>
<div id="percentile-method-infer" class="section level3">
<h3><span class="header-section-number">9.4.4</span> The percentile method with infer</h3>
<p>Recall the percentile method of looking at the middle 95% of values with the lower endpoint at the 2.5<sup>th</sup> percentile and the upper endpoint at the 97.5<sup>th</sup> percentile. This can be done with <code>infer</code> using the <code>get_confidence_interval()</code> function. You can also use the alias <code>get_ci()</code> if you’d like the short version. That’s what we use here.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_ci</span>(<span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">type =</span> <span class="st">&quot;percentile&quot;</span>)</code></pre>
<pre><code># A tibble: 1 x 2
   `2.5%` `97.5%`
    &lt;dbl&gt;   &lt;dbl&gt;
1 1991.16 1999.46</code></pre>
<p>These options are the default values for <code>level</code> and <code>type</code> so we can also just do:</p>
<pre class="sourceCode r"><code class="sourceCode r">percentile_ci &lt;-<span class="st"> </span>bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_ci</span>()
percentile_ci</code></pre>
<pre><code># A tibble: 1 x 2
   `2.5%` `97.5%`
    &lt;dbl&gt;   &lt;dbl&gt;
1 1991.16 1999.46</code></pre>
<p>Now we see where the values obtained in Section <a href="9-confidence-intervals.html#confidence-intervals">9</a> come from. Using the percentile method, our range of plausible values for the mean year of US pennies in circulation in 2019 is 1991.159 to 1999.46. We can further use the <code>visualize()</code> function and the <code>shade_confidence_interval()</code> function, or alias <code>shade_ci()</code>, to view this. We use the <code>endpoints</code> argument to be those stored with name <code>percentile_ci</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_ci</span>(<span class="dt">endpoints =</span> percentile_ci)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-304-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>You can see that 95% of the data stored in the <code>stat</code> variable in <code>bootstrap_distribution</code> falls between the two endpoints with 2.5% to the left outside of the shading and 2.5% to the right outside of the shading. The cut-off points that provide our range are shown with the darker lines.</p>
<p>Note that you can change the colors here as you wish using the <code>color</code> and <code>fill</code> arguments.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_ci</span>(<span class="dt">endpoints =</span> percentile_ci,
           <span class="dt">color =</span> <span class="st">&quot;brown&quot;</span>,
           <span class="dt">fill =</span> <span class="st">&quot;khaki&quot;</span>)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-306-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_ci</span>(<span class="dt">endpoints =</span> percentile_ci,
           <span class="dt">color =</span> <span class="st">&quot;hotpink&quot;</span>,
           <span class="dt">fill =</span> <span class="ot">NULL</span>)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-308-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
</div>
<div id="the-standard-error-method-with-infer" class="section level3">
<h3><span class="header-section-number">9.4.5</span> The standard error method with infer</h3>
<p>Recall the formula <span class="math inline">\(\bar{x} \pm (multiplier * SE),\)</span> where <span class="math inline">\(\bar{x}\)</span> is our original sample mean and <span class="math inline">\(SE\)</span> stands for <strong>standard error</strong> and corresponds to the standard deviation of the bootstrap distribution. This is the formula for using the standard error method for calculating a confidence interval.</p>
<p>The <span class="math inline">\(multiplier\)</span> is automatically calculated when <code>level</code> is provided with <code>level = 0.95</code> being the default. (95% of the values in a standard normal distribution fall within 1.96 standard deviations of the mean, so <span class="math inline">\(multiplier = 1.96\)</span> for <code>level = 0.95</code>, for example.) As mentioned, this formula assumes that the bootstrap distribution is symmetric and bell-shaped. This is often the case with bootstrap distributions, especially those in which the original distribution of the sample is not highly skewed.</p>
<p>This <span class="math inline">\(\bar{x} \pm (multiplier * SE)\)</span> formula is implemented in the <code>get_ci()</code> function as shown with our pennies problem using the bootstrap distribution’s variability as an approximation for the sampling distribution’s variability. We’ll see more on this approximation shortly.</p>
<p>Note that the center of the confidence interval (the <code>point_estimate</code>) must be provided for the standard error confidence interval.</p>
<pre class="sourceCode r"><code class="sourceCode r">standard_error_ci &lt;-<span class="st"> </span>bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_ci</span>(<span class="dt">type =</span> <span class="st">&quot;se&quot;</span>, <span class="dt">point_estimate =</span> x_bar)
standard_error_ci</code></pre>
<pre><code># A tibble: 1 x 2
    lower   upper
    &lt;dbl&gt;   &lt;dbl&gt;
1 1991.25 1999.63</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_ci</span>(<span class="dt">endpoints =</span> standard_error_ci)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-311-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>As noted in Section <a href="9-confidence-intervals.html#confidence-intervals">9</a> both methods produce similar confidence intervals.</p>
<table>
<thead>
<tr class="header">
<th>Percentile</th>
<th>Standard error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\([1991.16, 1999.46]\)</span></td>
<td><span class="math inline">\([1991.25, 1999.63]\)</span></td>
</tr>
</tbody>
</table>
<p>The <code>[lower, upper]</code> notation here corresponds to the <code>lower</code> value being the smallest included entry in the confidence interval and <code>upper</code> being the largest included entry in the confidence interval.</p>
<hr />
</div>
</div>
<div id="one-prop-ci" class="section level2">
<h2><span class="header-section-number">9.5</span> Case study: Revisiting the red ball example</h2>
<p>Let’s revisit our exercise of trying to estimate the proportion of red balls in the bowl from Chapter <a href="8-sampling.html#sampling">8</a>. We are now interested in determining a confidence interval for the population parameter <span class="math inline">\(p\)</span>, the proportion of balls that are red out of the total <span class="math inline">\(N = 2400\)</span> red and white balls.</p>
<p>We will use the first sample reported from Ilyas and Yohan in Subsection <a href="8-sampling.html#student-shovels">8.1.3</a> for our point estimate. They observed 21 red balls out of the 50 in their shovel. This data is stored in the <code>tactile_shovel_1</code> data frame in the <code>moderndive</code> package.</p>
<!-- Albert: Need to include this in the package? Or should we just generate
these for all the examples for use later with interpretation and not include it? -->
<pre class="sourceCode r"><code class="sourceCode r">tactile_shovel_<span class="dv">1</span></code></pre>
<pre><code># A tibble: 50 x 1
   color
   &lt;chr&gt;
 1 red  
 2 red  
 3 red  
 4 white
 5 white
 6 white
 7 white
 8 white
 9 red  
10 white
# … with 40 more rows</code></pre>
<div id="observed-statistic" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Observed statistic</h3>
<p>To compute the proportion that are red in this data we can use the <code>specify() %&gt;% calculate()</code> workflow. Note the use of the <code>success</code> argument here to clarify which of the two colors <code>&quot;red&quot;</code> or <code>&quot;white&quot;</code> we are interested in.</p>
<pre class="sourceCode r"><code class="sourceCode r">p_hat &lt;-<span class="st"> </span>tactile_shovel_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)
p_hat</code></pre>
<pre><code># A tibble: 1 x 1
   stat
  &lt;dbl&gt;
1  0.42</code></pre>
</div>
<div id="one-prop-boot" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Bootstrap distribution for one proportion</h3>
<p>Next, we want to calculate many different bootstrap samples and their corresponding bootstrap statistic (the proportion of red balls). We’ve done 1000 in the past, but let’s go up to 10,000 now to better see the resulting distribution. Recall that this is done by including a <code>generate()</code> function call in the middle of our pipeline:</p>
<pre class="sourceCode r"><code class="sourceCode r">tactile_shovel_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">10000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</code></pre>
<p>This results in 50 rows for each of the 10,000 replicates. Lastly, we finish the <code>infer</code> pipeline by adding back in the <code>calculate()</code> step.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_props &lt;-<span class="st"> </span>tactile_shovel_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">10000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)</code></pre>
<p>Let’s <code>visualize()</code> what the resulting bootstrap distribution looks like as a histogram. We’ve adjusted the number of bins here as well to better see the resulting shape.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_props, <span class="dt">bins =</span> <span class="dv">20</span>)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-320-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>We see that the resulting distribution is symmetric and bell-shaped so it doesn’t much matter which confidence interval method we choose. Let’s use the standard error method to create a 95% confidence interval.</p>
<pre class="sourceCode r"><code class="sourceCode r">standard_error_ci &lt;-<span class="st"> </span>bootstrap_props <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_ci</span>(<span class="dt">type =</span> <span class="st">&quot;se&quot;</span>, <span class="dt">level =</span> <span class="fl">0.95</span>, <span class="dt">point_estimate =</span> p_hat)
standard_error_ci</code></pre>
<pre><code># A tibble: 1 x 2
     lower    upper
     &lt;dbl&gt;    &lt;dbl&gt;
1 0.282244 0.557756</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_props, <span class="dt">bins =</span> <span class="dv">25</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">shade_ci</span>(<span class="dt">endpoints =</span> standard_error_ci)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-323-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>We are “95% confident” that the true proportion of red balls in the bowl is between 0.282 and 0.558.</p>
</div>
</div>
<div id="interpreting-the-confidence-interval" class="section level2">
<h2><span class="header-section-number">9.6</span> Interpreting the confidence interval</h2>
<p>One key to working with confidence intervals is to also understand how best to interpret them. From the previous example, this level of confidence (95%) is based on the standard error-based method including the true proportion 95% of the time if many different samples (not just the one we used) were collected and confidence intervals were created following this standard error-based method. Let’s dig into what this means further by exploring the confidence intervals based on other samples to see how they compare to the one we just calculated. By the end of this section, you should have an understanding as to what “95% confident” means and how best to use that knowledge when you see that language used in other contexts.</p>
<p>As shown above in Subsection <a href="9-confidence-intervals.html#one-prop-boot">9.5.2</a>, one range of plausible values for the population proportion of red balls (the true proportion of all red balls in the entire bowl), denoted by <span class="math inline">\(p\)</span>, is <span class="math inline">\([0.28, 0.56]\)</span>. Recall that this confidence interval is based on bootstrapping using <code>tactile_shovel_1</code>.</p>
<p>To best understand how to interpret a confidence interval, it is important to see how the process works when we have a known population parameter. Recall the <code>bowl</code> data frame in the <code>moderndive</code> package contains our population of interest. We can calculate the proportion of red balls in this population to get the value of <span class="math inline">\(p\)</span>. Remember this isn’t usually the case of knowing the population parameter, but we’ll see why this is useful for our build-up shortly. Let’s do this two ways to review both the <code>infer</code> and <code>dplyr</code> pipelines:</p>
<pre class="sourceCode r"><code class="sourceCode r">bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)</code></pre>
<pre><code># A tibble: 1 x 1
   stat
  &lt;dbl&gt;
1 0.375</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))</code></pre>
<pre><code># A tibble: 1 x 1
   stat
  &lt;dbl&gt;
1 0.375</code></pre>
<p>Both methods return 0.375 as the proportion of red balls in the population of all balls in the bowl. So did our “95% confident” guess above of <span class="math inline">\([0.28, 0.56]\)</span> contain the “true value” for the population?</p>
<p>Yes, the population proportion (0.375) does fall in this confidence interval. If we had a different sample of size 50 and constructed a confidence interval using the same method, would we be guaranteed that it contained the population parameter value as well? Let’s try it out by pulling another sample from <code>bowl</code> of size 50:</p>
<pre class="sourceCode r"><code class="sourceCode r">bowl_sample_<span class="dv">2</span> &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>)</code></pre>
<p>Note the use of the <code>sample_n()</code> function in the <code>dplyr</code> package here. This does the same thing as <code>rep_sample_n(reps = 1)</code> but omits the extra <code>replicate</code> column.</p>
<p>We next create an <code>infer</code> pipeline to generate a standard error-based 95% confidence interval for <span class="math inline">\(p\)</span>. Recall that we first need a <code>point_estimate</code> to act as the center of our standard error-based confidence interval. We calculate this with name <code>prop_red_2</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">prop_red_<span class="dv">2</span> &lt;-<span class="st"> </span>bowl_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)
standard_error_ci_<span class="dv">2</span> &lt;-<span class="st"> </span>bowl_sample_<span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_ci</span>(<span class="dt">type =</span> <span class="st">&quot;se&quot;</span>, <span class="dt">point_estimate =</span> prop_red_<span class="dv">2</span>)
standard_error_ci_<span class="dv">2</span> </code></pre>
<pre><code># A tibble: 1 x 2
     lower    upper
     &lt;dbl&gt;    &lt;dbl&gt;
1 0.233227 0.486773</code></pre>
<p>This new confidence interval also contains the value of <span class="math inline">\(p\)</span>. Let’s further investigate by repeating this process 100 times to get 100 different confidence intervals derived from 100 different samples of the population <code>bowl</code>. Each sample will have a size of 50 just as the original sample. We will plot each of these confidence intervals as horizontal lines. At the center of each confidence interval is the point estimate denoted by a dot. We will also show a red line corresponding to the known population value of 0.375 red balls.</p>
<div class="figure" style="text-align: center"><span id="fig:reliable-se"></span>
<img src="ismaykim_files/figure-html/reliable-se-1.png" alt="Reliability of 95 percent confidence intervals" width="\textwidth" />
<p class="caption">
FIGURE 9.10: Reliability of 95 percent confidence intervals
</p>
</div>
<p>Of the 100 confidence intervals based on samples of size <span class="math inline">\(n = 50\)</span>, 95 of them captured the population mean <span class="math inline">\(p = 0.375\)</span>, whereas 5 of them did not include it. If we repeated this process of building confidence intervals more times with more samples, we’d expect 95% of them to contain the population parameter <span class="math inline">\(p\)</span>. In other words, the procedure we have used to generate confidence intervals is “95% reliable” in that we can expect it to include the true population parameter 95% of the time if the process is repeated.</p>
<p>To further accentuate this point, let’s perform a similar procedure using 90% confidence intervals instead. This time we will use the percentile method instead of the standard error method for computing the confidence intervals.</p>
<div class="figure" style="text-align: center"><span id="fig:reliable-perc"></span>
<img src="ismaykim_files/figure-html/reliable-perc-1.png" alt="Reliability of 90 percent confidence intervals" width="\textwidth" />
<p class="caption">
FIGURE 9.11: Reliability of 90 percent confidence intervals
</p>
</div>
<p>Of the 100 confidence intervals based on samples of size <span class="math inline">\(n = 50\)</span>, 91 of them captured the population proportion <span class="math inline">\(p = 0.375\)</span>, whereas 9 of them did not include it. Repeating this process for more samples would result in us getting closer and closer to 90% of the confidence intervals including the true value. It is common to say while interpreting a confidence interval to be “95% confident” or “90% confident” that the true value falls within the range of the specified confidence interval. We will use this “confident” language throughout the rest of this chapter, but remember that it has more to do with a measure of the reliability of the building process.</p>
<div id="back-to-our-pennies-example" class="section level4 unnumbered">
<h4>Back to our pennies example</h4>
<p>After this elaboration on what the level corresponds to in a confidence interval, let’s conclude by providing an interpretation of the original confidence interval result we found in Subsection <a href="9-confidence-intervals.html#infer-ci">9.4.3</a>.</p>
<p><strong>Interpretation:</strong> We are 95% confident that the true mean year of pennies in circulation in 2019 is between 1991.159 to 1999.46. This level of confidence is based on the percentile-based method including the true mean 95% of the time if many different samples (not just the one we used) were collected and confidence intervals were created.</p>
</div>
<div id="the-width-of-confidence-intervals" class="section level3 unnumbered">
<h3>The width of confidence intervals</h3>
<div id="the-impact-of-confidence-levels" class="section level4 unnumbered">
<h4>The impact of confidence levels</h4>
<p>When looking at the relative sizes of the orange horizontal lines in Figure <a href="9-confidence-intervals.html#fig:reliable-se">9.10</a> with 95% confidence intervals and Figure <a href="9-confidence-intervals.html#fig:reliable-perc">9.11</a> with 90% confidence intervals, does anything stand out in terms of the width of the intervals to you? The statement of confidence in terms of the level should match with what you expect of the word “confident.” If someone says they are 99% confident about the high temperature between one value and another for the next day, we’d expect that range to be higher than if they said they were only 80% confident, right?</p>
<p>To elaborate on this a bit, if we wanted to make a guess as to what the forecasted summertime high temperature in Brussels, Belgium would be for a day in July, we could say pretty confidently that the high temperature wouldn’t be below 55° F (approximately 13° C) and that it wouldn’t be above 72° F (approximately 22° C). Let’s say we are 90% confident for a given day about this claim. What would we need to do to this range to increase our level of confidence?</p>
<p>We’d need to increase it! To be more confident about the range of plausible values for our high temperature, we need to add in more possible temperatures since we might have a cold streak or an unseasonably warm day.</p>
<p>What if we wanted to be a little less confident and say have a 50-50 chance of guessing at what the high temperature would be. Well, if we are OK being wrong 50% of the time, we could guess something in a much narrower range for plausible values of the high temperature. Something like [61° F, 66° F] (approximately [16° C, 19° C]) might be a 50% confident guess, say. By narrowing our range, we’ve decreased our level of confidence. This analogy relates well (maybe not exactly) to confidence intervals in statistics.</p>
<p><strong>Higher confidence levels tend to produce wider confidence intervals.</strong></p>
<p>Let’s play with do a little more analysis using the <code>bowl</code> data to construct 80%, 95%, and 99% confidence intervals here to drill this idea home. We’ll focus on the percentile-based method though a similar analysis could be done for the standard error-based method. Let’s calculate 100 confidence intervals of each of these three different levels and then look at the median and mean length of these intervals. These will be stored in the <code>perc_cis_by_level</code> data frame.</p>
<!-- Albert: Should we load these into the moderndive package too so that readers can explore them a bit? -->
<p>Let’s take a look into what the <code>perc_cis_by_level</code> data frame looks like and how a sample of 10 different confidence intervals each from the 80%, 95%, and 99% levels compare visually in terms of length. Then, we’ll start computing some widths of the confidence intervals. Then we’ll head into calculating the mean and median widths across the three different levels.</p>


<p><img src="ismaykim_files/figure-html/unnamed-chunk-329-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>We see that the sample proportion of reds varies in the <code>point_estimate</code> column with varying <code>lower</code> and <code>upper</code> bounds as well depending on the variability of the bootstrap distribution. The width of the confidence intervals appears to increase from left to right going from 80% confidence levels to 95% and then to 99%. Let’s now compute the confidence interval (CI) width for each of these intervals and then get the median and mean length.</p>
<pre class="sourceCode r"><code class="sourceCode r">percentile_cis_by_level <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">width =</span> upper <span class="op">-</span><span class="st"> </span>lower) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(confidence_level) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">median_width =</span> <span class="kw">median</span>(width),
            <span class="dt">mean_width =</span> <span class="kw">mean</span>(width))</code></pre>
<pre><code># A tibble: 3 x 3
  confidence_level median_width mean_width
             &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
1               80     0.16       0.16906 
2               95     0.280000   0.266255
3               99     0.340100   0.341841</code></pre>
<p>As expected, as the confidence level increases, the width of the corresponding confidence interval also increases. To be more confident, we need to increase the range of plausible values.</p>
</div>
<div id="the-impact-of-sample-size" class="section level4 unnumbered">
<h4>The impact of sample size</h4>
<p>We can also observe the impact of sample size on these calculations and make some generalizations. You’ll see in Subsection <a href="9-confidence-intervals.html#theory-ci">9.8.2</a> some reasons via mathematical formulas for the behavior of confidence interval width and changing sample sizes too.</p>
<p>Let’s hold the confidence level fixed at 90% using the percentile-based method, but take samples of size 25, 50, and 100 corresponding to the different sizes of the shovels available to us in Chapter <a href="8-sampling.html#sampling">8</a>. Do you expect smaller sample sizes to produce wider confidence intervals? Or should larger sample sizes produce wider ones? Let’s investigate.</p>
<p>Recall the <code>virtual_samples_25</code>, <code>virtual_samples_50</code>, and <code>virtual_samples_100</code> data frames that were calculated in Chapter <a href="8-sampling.html#sampling">8</a>. As a reminder, here’s the code needed to compute them.</p>
<pre class="sourceCode r"><code class="sourceCode r">virtual_samples_<span class="dv">25</span> &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
balls_samples_<span class="dv">50</span> &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)
balls_samples_<span class="dv">100</span> &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">100</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</code></pre>
<!-- Albert: What about these confidence intervals for different sample sizes in the moderndive package? -->
<p>As we did when investigating the role of confidence level, confidence intervals for each of the different 1000 samples of each of these three sample sizes has been saved into the <code>percentile_cis_by_n</code> data frame. Let’s investigate width visually first and then look at the median and mean length of these intervals.</p>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-333-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r">percentile_cis_by_n <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">width =</span> upper <span class="op">-</span><span class="st"> </span>lower) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(sample_size) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">median_width =</span> <span class="kw">median</span>(width),
            <span class="dt">mean_width =</span> <span class="kw">mean</span>(width))</code></pre>
<pre><code># A tibble: 3 x 3
  sample_size median_width mean_width
        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
1          25     0.32       0.310986
2          50     0.22       0.222539
3         100     0.160000   0.157986</code></pre>
<p>So as the sample size increases the width of our confidence intervals decreases. This intuitively makes sense since as we have larger samples we are getting closer and closer to the actual size of the population. As we get closer to the actual size of the population, we will have less and less variability in the sample proportion red since there will be less and less variability in the samples pulled from the population.</p>
<!-- A good learning check might be to have the readers calculate confidence intervals when n = 1000, 2000, 2400. To their astonishment (maybe), they'll see that the size of the confidence interval is 0 when they get to 2400. -->
<hr />
</div>
</div>
</div>
<div id="case-study-two-prop-ci" class="section level2">
<h2><span class="header-section-number">9.7</span> Case study: Comparing two proportions</h2>
<p>Let’s now look into another example where the <code>infer</code> pipeline really shows off its power by looking at two variables. We’ll have a response and an explanatory variable instead of just the one variable we’ve seen so far in the bowl of balls and pennies examples.</p>
<p>If you see someone else yawn, are you more likely to yawn? In an <a href="http://www.discovery.com/tv-shows/mythbusters/mythbusters-database/yawning-contagious/">episode</a> of the show <em>Mythbusters</em>, they tested the myth that yawning is contagious. The snippet from the show is available to view in the United States on the Discovery Network website <a href="https://www.discovery.com/tv-shows/mythbusters/videos/is-yawning-contagious">here</a>. More information about the episode is also available on IMDb <a href="https://www.imdb.com/title/tt0768479/">here</a>.</p>
<p>Fifty adults who thought they were being considered for an appearance on the show were interviewed by a show recruiter (“confederate”) who either yawned or did not. Participants then sat by themselves in a large van and were asked to wait. While in the van, the Mythbusters watched via hidden camera to see if the unaware participants yawned. The data frame containing the results is available at <code>mythbusters_yawn</code> in the <code>moderndive</code> package. Let’s check it out.</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn</code></pre>
<pre><code># A tibble: 50 x 3
    subj group   yawn 
   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
 1     1 seed    yes  
 2     2 control yes  
 3     3 seed    no   
 4     4 seed    yes  
 5     5 seed    no   
 6     6 control no   
 7     7 seed    yes  
 8     8 control no   
 9     9 control no   
10    10 seed    no   
# … with 40 more rows</code></pre>
<ul>
<li>The participant ID is stored in the <code>subj</code> variable with values of 1 to 50.</li>
<li>The <code>group</code> variable is either <code>&quot;seed&quot;</code> for when a confederate was trying to influence the participant or <code>&quot;control&quot;</code> if a confederate did not interact with the participant.</li>
<li>The <code>yawn</code> variable is either <code>&quot;yes&quot;</code> if the participant yawned or <code>&quot;no&quot;</code> if the participant did not yawn.</li>
</ul>
<p>We can use the <code>janitor</code> package to get a glimpse into this data in a table format:</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tabyl</span>(group, yawn) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">adorn_percentages</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">adorn_pct_formatting</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># To show original counts</span>
<span class="st">  </span><span class="kw">adorn_ns</span>()</code></pre>
<pre><code>   group         no        yes
 control 75.0% (12) 25.0%  (4)
    seed 70.6% (24) 29.4% (10)</code></pre>
<p>We are interested in comparing the proportion of those that yawned after seeing a seed versus those that yawned with no seed interaction. We’d like to see if the difference between these two proportions is significantly larger than 0. If so, we’d have evidence to support the claim that yawning is contagious based on this study.</p>
<p>In looking over this problem, we can make note of some important details to include in our <code>infer</code> pipeline:</p>
<ul>
<li>We are calling a <code>success</code> having a <code>yawn</code> value of <code>&quot;yes&quot;</code>.</li>
<li>Our response variable will always correspond to the variable used in the <code>success</code> so the response variable is <code>yawn</code>.</li>
<li>The explanatory variable is the other variable of interest here: <code>group</code>.</li>
</ul>
<p>To summarize, we are looking to see the examine the relationship between yawning and whether or not the participant saw a seed yawn or not.</p>
<div id="compute-the-point-estimate" class="section level3">
<h3><span class="header-section-number">9.7.1</span> Compute the point estimate</h3>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group)</code></pre>
<pre><code>Error: A level of the response variable `yawn` needs to be specified
for the `success` argument in `specify()`.</code></pre>
<p>Note that the <code>success</code> argument must be specified in situations such as this where the response variable has only two levels.</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>)</code></pre>
<pre><code>Response: yawn (factor)
Explanatory: group (factor)
# A tibble: 50 x 2
   yawn  group  
   &lt;fct&gt; &lt;fct&gt;  
 1 yes   seed   
 2 yes   control
 3 no    seed   
 4 yes   seed   
 5 no    seed   
 6 no    control
 7 yes   seed   
 8 no    control
 9 no    control
10 no    seed   
# … with 40 more rows</code></pre>
<p>We next want to calculate the statistic of interest for our sample. This corresponds to the difference in the proportion of successes.</p>
<pre class="sourceCode r"><code class="sourceCode r">mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>)</code></pre>
<pre><code>Error: Statistic is based on a difference; specify the `order` in which to
subtract the levels of the explanatory variable.</code></pre>
<p>We see another error here. To further check to make sure that R knows exactly what we are after, we need to provide the <code>order</code> in which R should subtract these proportions of successes. As the error message states, we’ll want to put <code>&quot;seed&quot;</code> first after <code>c()</code> and then <code>&quot;control&quot;</code>: <code>order = c(&quot;seed&quot;, &quot;control&quot;)</code>. Our point estimate is thus calculated:</p>
<pre class="sourceCode r"><code class="sourceCode r">obs_diff &lt;-<span class="st"> </span>mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;seed&quot;</span>, <span class="st">&quot;control&quot;</span>))
obs_diff</code></pre>
<pre><code># A tibble: 1 x 1
       stat
      &lt;dbl&gt;
1 0.0441176</code></pre>
<p>This value represents the proportion of those that yawned after seeing a seed yawn (0.2941) minus the proportion of those that yawned with not seeing a seed (0.25).</p>
</div>
<div id="bootstrap-distribution" class="section level3">
<h3><span class="header-section-number">9.7.2</span> Bootstrap distribution</h3>
<p>Our next step in building a confidence interval is to create a bootstrap distribution of statistics (differences in proportions of successes). We saw how it works with both a single variable in computing bootstrap means in Subsection <a href="9-confidence-intervals.html#bootstrap-process">9.4</a> and in computing bootstrap proportions in Section <a href="9-confidence-intervals.html#one-prop-ci">9.5</a>, but we haven’t yet worked with bootstrapping involving multiple variables though.</p>
<p>In the <code>infer</code> package, bootstrapping with multiple variables means that each <strong>row</strong> is potentially resampled. Let’s investigate this by looking at the first few rows of <code>mythbusters_yawn</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mythbusters_yawn)</code></pre>
<pre><code># A tibble: 6 x 3
   subj group   yawn 
  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
1     1 seed    yes  
2     2 control yes  
3     3 seed    no   
4     4 seed    yes  
5     5 seed    no   
6     6 control no   </code></pre>
<p>When we bootstrap this data, we are potentially pulling the subject’s readings multiple times. Thus, we could see the entries of <code>&quot;seed&quot;</code> for <code>group</code> and <code>&quot;no&quot;</code> for <code>yawn</code> together in a new row in a bootstrap sample. This is further seen by exploring the <code>sample_n()</code> function in <code>dplyr</code> on this smaller 6-row data frame comprised of <code>head(mythbusters_yawn)</code>. The <code>sample_n()</code> function can perform this bootstrapping procedure and is similar to the <code>rep_sample_n()</code> function in <code>infer</code>, except that it is not <code>rep</code>eated but rather only performs one sample with or without replacement.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mythbusters_yawn) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">6</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code># A tibble: 6 x 3
   subj group   yawn 
  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
1     4 seed    yes  
2     6 control no   
3     3 seed    no   
4     5 seed    no   
5     3 seed    no   
6     4 seed    yes  </code></pre>
<p>We can see that in this bootstrap sample generated from the first six rows of <code>mythbusters_yawn</code>, we have some rows repeated. The same is true when we perform the <code>generate()</code> step in <code>infer</code> as done below.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution &lt;-<span class="st"> </span>mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> yawn <span class="op">~</span><span class="st"> </span>group, <span class="dt">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;seed&quot;</span>, <span class="st">&quot;control&quot;</span>))</code></pre>
<!-- A challenging learning check for those {dplyr} diehards is to get these values without using {infer}. It takes a double group_by() and some trickery, but
could be a good exercise for those that don't quite see the power of {infer}. -->
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">visualize</span>(<span class="dt">bins =</span> <span class="dv">20</span>)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-345-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>This distribution is roughly symmetric and bell-shaped but isn’t quite there. Let’s use the percentile-based method to compute a 95% confidence interval for the true difference in the proportion of those that yawn with and without a seed presented. The arguments are explicitly listed here but remember they are the defaults and simply <code>get_ci()</code> can be used.</p>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">get_ci</span>(<span class="dt">type =</span> <span class="st">&quot;percentile&quot;</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre>
<pre><code># A tibble: 1 x 2
     `2.5%`  `97.5%`
      &lt;dbl&gt;    &lt;dbl&gt;
1 -0.202309 0.304763</code></pre>
<p>The confidence interval shown here includes the value of 0. We’ll see in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a> further what this means in terms of this difference being statistically significant or not, but let’s examine a bit here first. The range of plausible values for the difference in the proportion of those that yawned with and without a seed is between -0.202 and 0.305.</p>
<p>Therefore, we are not sure which proportion is larger. Some of the bootstrap statistics showed the proportion without a seed to be higher and others showed the proportion with a seed to be higher. If the confidence interval was entirely above zero, we would be relatively sure (about “95% confident”) that the seed group had a higher proportion of yawning than the control group.</p>
<p>Note that this all relates to the importance of denoting the <code>order</code> argument in the <code>calculate()</code> function. Since we specified <code>&quot;seed&quot;</code> and then <code>&quot;control&quot;</code> positive values for the statistic correspond to the <code>&quot;seed&quot;</code> proportion being higher, whereas negative values correspond to the <code>&quot;control&quot;</code> group being higher.</p>
<p>We, therefore, have evidence via this confidence interval suggesting that the conclusion from the Mythbusters show that “yawning is contagious” being “confirmed” is not statistically appropriate.</p>
<!-- Good learning check is to ask for an interpretation using the format above for this Mythbusters example. -->
<hr />
</div>
</div>
<div id="ci-conclusion" class="section level2">
<h2><span class="header-section-number">9.8</span> Conclusion</h2>
<div id="comparing-bootstrap-and-sampling-distributions" class="section level3">
<h3><span class="header-section-number">9.8.1</span> Comparing bootstrap and sampling distributions</h3>
<p>Earlier in this chapter, we mentioned that the variability of the sampling distribution is often well-approximated by the variability of the bootstrap distribution. Since we’ve computed both of these distributions for the <code>bowl</code> example, let’s dig into both of them further to make comparisons.</p>
<div id="sampling-distribution" class="section level4 unnumbered">
<h4>Sampling distribution</h4>
<p>Let’s assume that <code>bowl</code> represents our population of interest. We’ll next go over again how to create a sampling distribution for the population proportion of red balls, denoted by <span class="math inline">\(p\)</span>, using the <code>rep_sample_n()</code> function seen in Chapter <a href="8-sampling.html#sampling">8</a>. Let’s use a mega-virtual shovel of size 200 here. First, we will create 1000 samples from the <code>bowl</code> data frame.</p>
<pre class="sourceCode r"><code class="sourceCode r">thousand_samples &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">200</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</code></pre>
<p>When creating a sampling distribution, we do not replace the items when we create each sample. This is in contrast to the bootstrap distribution. It’s important to remember that the sampling distribution is sampling <strong>without</strong> replacement from the population to better understand sample-to-sample variability, whereas the bootstrap distribution is sampling <strong>with</strong> replacement from our original sample to better understand potential sample-to-sample variability. For the sampling distribution, we have access to the population whereas with the bootstrap distribution we are only going to pull ourselves up from our bootstraps using the single sample.</p>
<p>After sampling from <code>bowl</code> 1000 times, we next want to compute the proportion of red balls for each of the 1000 samples:</p>
<pre class="sourceCode r"><code class="sourceCode r">sampling_distribution &lt;-<span class="st"> </span>thousand_samples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">stat =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(sampling_distribution, <span class="kw">aes</span>(<span class="dt">x =</span> stat)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">10</span>, <span class="dt">fill =</span> <span class="st">&quot;salmon&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-350"></span>
<img src="ismaykim_files/figure-html/unnamed-chunk-350-1.png" alt="Sampling distribution for proportion red for n=200 samples of balls" width="\textwidth" />
<p class="caption">
FIGURE 9.12: Sampling distribution for proportion red for n=200 samples of balls
</p>
</div>
<p>We can also examine the variability in this sampling distribution by calculating the standard deviation of the <code>stat</code> column. Remember that the standard deviation of the sampling distribution is the <strong>standard error</strong>, frequently denoted as <code>se</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">sampling_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="kw">sd</span>(stat))</code></pre>
<pre><code># A tibble: 1 x 1
         se
      &lt;dbl&gt;
1 0.0323101</code></pre>
</div>
<div id="bootstrap-distribution-1" class="section level4 unnumbered">
<h4>Bootstrap distribution</h4>
<p>Let’s now see how the shape of the bootstrap distribution compares to that of the sampling distribution. We’ll shade the bootstrap distribution blue to further assist with remembering which is which, with the sampling distribution shaded salmon color. Let’s walk through the steps needed with the <code>infer</code> pipeline to create the bootstrap distribution. We first need a sample of size 200 pulled from the <code>bowl</code> to give us a starting sample:</p>
<pre class="sourceCode r"><code class="sourceCode r">sample_<span class="dv">200</span> &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">200</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</code></pre>
<ol style="list-style-type: decimal">
<li><code>specify</code> variables</li>
</ol>
<p>We first identify which variable(s) we are interested in for our inferential analysis.</p>
<pre class="sourceCode r"><code class="sourceCode r">sample_<span class="dv">200</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>)</code></pre>
<pre><code>Error: A level of the response variable `color` needs to be specified for the
`success` argument in `specify()`.</code></pre>
<p>The <code>infer</code> package sends an error here that we need to tell it which of the possible <code>color</code> options we’d like to call a <code>success.</code></p>
<pre class="sourceCode r"><code class="sourceCode r">sample_<span class="dv">200</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<pre><code>Response: color (factor)
# A tibble: 200 x 1
   color
   &lt;fct&gt;
 1 white
 2 white
 3 white
 4 white
 5 white
 6 white
 7 white
 8 white
 9 white
10 red  
# … with 190 more rows</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><code>generate</code> bootstrap replicates</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">sample_<span class="dv">200</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</code></pre>
<pre><code>Response: color (factor)
# A tibble: 200,000 x 2
# Groups:   replicate [1,000]
   replicate color
       &lt;int&gt; &lt;fct&gt;
 1         1 white
 2         1 white
 3         1 red  
 4         1 red  
 5         1 white
 6         1 white
 7         1 white
 8         1 white
 9         1 red  
10         1 white
# … with 199,990 more rows</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><code>calculate</code> statistics</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution_n_<span class="dv">200</span> &lt;-<span class="st"> </span>sample_<span class="dv">200</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">specify</span>(<span class="dt">formula =</span> color <span class="op">~</span><span class="st"> </span><span class="ot">NULL</span>, <span class="dt">success =</span> <span class="st">&quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;prop&quot;</span>)
bootstrap_distribution_n_<span class="dv">200</span></code></pre>
<pre><code># A tibble: 1,000 x 2
   replicate  stat
       &lt;int&gt; &lt;dbl&gt;
 1         1 0.36 
 2         2 0.365
 3         3 0.355
 4         4 0.38 
 5         5 0.31 
 6         6 0.305
 7         7 0.34 
 8         8 0.31 
 9         9 0.37 
10        10 0.335
# … with 990 more rows</code></pre>
<ol start="4" style="list-style-type: decimal">
<li><code>visualize</code> distribution of <code>stat</code>istics</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualize</span>(bootstrap_distribution_n_<span class="dv">200</span>, <span class="dt">bins =</span> <span class="dv">10</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>)</code></pre>
<p><img src="ismaykim_files/figure-html/unnamed-chunk-360-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p><em>Side-by-side</em></p>
<p>Now that we have both the sampling distribution and the bootstrap distribution, let’s put them on the same scales and examine their variability both visually and also by computing relevant standard deviations.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-361"></span>
<img src="ismaykim_files/figure-html/unnamed-chunk-361-1.png" alt="Comparing sampling and bootstrap distributions" width="\textwidth" />
<p class="caption">
FIGURE 9.13: Comparing sampling and bootstrap distributions
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">sampling_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="kw">sd</span>(stat))</code></pre>
<pre><code># A tibble: 1 x 1
         se
      &lt;dbl&gt;
1 0.0323101</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution_n_<span class="dv">200</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="kw">sd</span>(stat))</code></pre>
<pre><code># A tibble: 1 x 1
         se
      &lt;dbl&gt;
1 0.0344325</code></pre>
<p>Notice that the bootstrap distribution’s standard deviation is a good approximation for the standard error, the standard deviation of the sampling distribution. Note that while the standard deviations are similar, the center of the sampling distribution and the bootstrap distribution differ:</p>
<pre class="sourceCode r"><code class="sourceCode r">sampling_distribution <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_of_sampling_means =</span> <span class="kw">mean</span>(stat))</code></pre>
<pre><code># A tibble: 1 x 1
  mean_of_sampling_means
                   &lt;dbl&gt;
1                0.37501</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">bootstrap_distribution_n_<span class="dv">200</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_of_bootstrap_means =</span> <span class="kw">mean</span>(stat))</code></pre>
<pre><code># A tibble: 1 x 1
  mean_of_bootstrap_means
                    &lt;dbl&gt;
1                 0.34816</code></pre>
<p>Since the bootstrap distribution is centered at the original sample proportion, it doesn’t necessarily provide a good estimate of the overall population proportion <span class="math inline">\(p\)</span>, which we calculated to be 0.375. Notice that this value matches up well with the mean of the sampling distribution. This is actually an artifact of the Central Limit Theorem introduced in Chapter <a href="8-sampling.html#sampling">8</a>. The mean of the sampling distribution is expected to be the mean of the overall population.</p>
<p>The unfortunate fact though is that we don’t know the population mean in nearly all circumstances. The motivation of presenting it here was to show that the theory behind the Central Limit Theorem works using the tools you’ve worked with so far using the <code>ggplot2</code>, <code>dplyr</code>, <code>moderndive</code>, and <code>infer</code> packages.</p>
<p>If we aren’t able to use the sample mean as a good guess for the population mean, how should we best go about estimating what the population mean may be if we can only select samples from the population. We’ve now come full circle and can discuss the underpinnings of the confidence interval and ways to interpret it.</p>
<hr />
</div>
</div>
<div id="theory-ci" class="section level3">
<h3><span class="header-section-number">9.8.2</span> Theory-based confidence intervals</h3>
<p>When the bootstrap distribution has the nice symmetric, bell shape that we saw in the red balls example above, we can also use a formula to quantify the standard error. This provides another way to compute a confidence interval but is a little more tedious and mathematical. The steps are outlined below. We’ve also shown how we can use the confidence interval (CI) interpretation in this case as well to support your understanding of this tricky concept.</p>
<div id="procedure-for-building-a-theory-based-ci-for-p" class="section level4 unnumbered">
<h4>Procedure for building a theory-based CI for <span class="math inline">\(p\)</span></h4>
<p>To construct a theory-based confidence interval for <span class="math inline">\(p\)</span>, the unknown true population proportion we</p>
<ol style="list-style-type: decimal">
<li>Collect a sample of size <span class="math inline">\(n\)</span></li>
<li>Compute <span class="math inline">\(\widehat{p}\)</span></li>
<li>Compute the standard error <span class="math display">\[\text{SE} = \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></li>
<li>Compute the margin of error <span class="math display">\[\text{MoE} = 1.96 \cdot \text{SE} =  1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></li>
<li>Compute both end points of the confidence interval:
<ul>
<li>The lower end point <code>lower_ci</code>: <span class="math display">\[\widehat{p} - \text{MoE} = \widehat{p} - 1.96 \cdot \text{SE} = \widehat{p} - 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></li>
<li>The upper end point <code>upper_ci</code>: <span class="math display">\[\widehat{p} + \text{MoE} = \widehat{p} + 1.96 \cdot \text{SE} = \widehat{p} + 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\]</span></li>
</ul></li>
<li>Alternatively, you can succinctly summarize a 95% confidence interval for <span class="math inline">\(p\)</span> using the <span class="math inline">\(\pm\)</span> symbol:</li>
</ol>
<p><span class="math display">\[
\widehat{p} \pm \text{MoE} = \widehat{p} \pm 1.96 \cdot \text{SE} = \widehat{p} \pm 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}
\]</span></p>
</div>
<div id="confidence-intervals-based-on-33-tactile-samples" class="section level4 unnumbered">
<h4>Confidence intervals based on 33 tactile samples</h4>
<p>Let’s load the tactile sampling data for the 33 groups from Chapter <a href="8-sampling.html#sampling">8</a>. Recall this data was saved in the <code>tactile_prop_red</code> data frame included in the <code>moderndive</code> package.</p>
<!-- Albert: Load tactile_prop_red into moderndive package too? -->
<pre class="sourceCode r"><code class="sourceCode r">tactile_prop_red</code></pre>
<p>Let’s now apply the above procedure for constructing confidence intervals for <span class="math inline">\(p\)</span> using the data saved in <code>tactile_prop_red</code> by adding/modifying new columns using the <code>dplyr</code> package data wrangling tools seen in Chapter <a href="4-wrangling.html#wrangling">4</a>:</p>
<ol style="list-style-type: decimal">
<li>Rename <code>prop_red</code> to <code>p_hat</code>, the official name of the sample proportion</li>
<li>Make explicit the sample size <code>n</code> of <span class="math inline">\(n\)</span> = 50</li>
<li>the standard error <code>SE</code></li>
<li>the margin of error <code>MoE</code></li>
<li>the left endpoint of the confidence interval <code>lower_ci</code></li>
<li>the right endpoint of the confidence interval <code>upper_ci</code></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">conf_ints &lt;-<span class="st"> </span>tactile_prop_red <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">p_hat =</span> prop_red) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">n =</span> <span class="dv">50</span>,
    <span class="dt">SE =</span> <span class="kw">sqrt</span>(p_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_hat) <span class="op">/</span><span class="st"> </span>n),
    <span class="dt">MoE =</span> <span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE,
    <span class="dt">lower_ci =</span> p_hat <span class="op">-</span><span class="st"> </span>MoE,
    <span class="dt">upper_ci =</span> p_hat <span class="op">+</span><span class="st"> </span>MoE
  )
conf_ints</code></pre>


<p>Let’s plot:</p>
<ol style="list-style-type: decimal">
<li>These 33 confidence intervals for <span class="math inline">\(p\)</span>: from <code>lower_ci</code> to <code>upper_ci</code></li>
<li>The true population proportion <span class="math inline">\(p = 900 / 2400 = 0.375\)</span> with a red vertical line</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:tactile-conf-int"></span>
<img src="ismaykim_files/figure-html/tactile-conf-int-1.png" alt="33 confidence intervals based on 33 tactile samples of size n=50" width="\textwidth" />
<p class="caption">
FIGURE 9.14: 33 confidence intervals based on 33 tactile samples of size n=50
</p>
</div>
<p>We see that:</p>
<ul>
<li>In 31 cases, the confidence intervals “capture” the true <span class="math inline">\(p = 900 / 2400 = 0.375\)</span></li>
<li>In 2 cases, the confidence intervals do not “capture” the true <span class="math inline">\(p = 900 / 2400 = 0.375\)</span></li>
</ul>
<p>Thus, the confidence intervals capture the true proportion <span class="math inline">\(31 / 33\)</span> = 93.939% of the time using this theory-based methodology.</p>
</div>
<div id="confidence-intervals-based-on-100-virtual-samples" class="section level4 unnumbered">
<h4>Confidence intervals based on 100 virtual samples</h4>
<p>Let’s say however, we repeated the above 100 times, not tactilely, but virtually. Let’s do this only 100 times instead of 1000 like we did before so that the results can fit on the screen. Again, the steps for compute a 95% confidence interval for <span class="math inline">\(p\)</span> are:</p>
<ol style="list-style-type: decimal">
<li>Collect a sample of size <span class="math inline">\(n = 50\)</span> as we did in Chapter <a href="8-sampling.html#sampling">8</a></li>
<li>Compute <span class="math inline">\(\widehat{p}\)</span>: the sample proportion red of these <span class="math inline">\(n\)</span> = 50 balls</li>
<li>Compute the standard error <span class="math inline">\(\text{SE} = \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\)</span></li>
<li>Compute the margin of error <span class="math inline">\(\text{MoE} = 1.96 \cdot \text{SE} = 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\)</span></li>
<li>Compute both end points of the confidence interval:
<ul>
<li><code>lower_ci</code>: <span class="math inline">\(\widehat{p} - \text{MoE} = \widehat{p} - 1.96 \cdot \text{SE} = \widehat{p} - 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\)</span></li>
<li><code>upper_ci</code>: <span class="math inline">\(\widehat{p} + \text{MoE} = \widehat{p} + 1.96 \cdot \text{SE} = \widehat{p} +1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}\)</span></li>
</ul></li>
</ol>
<p>Run the following three steps, being sure to <code>View()</code> the resulting data frame after each step so you can convince yourself of what’s going on:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># First: Take 100 virtual samples of n=50 balls</span>
virtual_samples &lt;-<span class="st"> </span>bowl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">100</span>)

<span class="co"># Second: For each virtual sample compute the proportion red</span>
virtual_prop_red &lt;-<span class="st"> </span>virtual_samples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)

<span class="co"># Third: Compute the 95% confidence interval as above</span>
virtual_prop_red &lt;-<span class="st"> </span>virtual_prop_red <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">p_hat =</span> prop_red) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">n =</span> <span class="dv">50</span>,
    <span class="dt">SE =</span> <span class="kw">sqrt</span>(p_hat<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p_hat)<span class="op">/</span>n),
    <span class="dt">MoE =</span> <span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE,
    <span class="dt">lower_ci =</span> p_hat <span class="op">-</span><span class="st"> </span>MoE,
    <span class="dt">upper_ci =</span> p_hat <span class="op">+</span><span class="st"> </span>MoE
  )</code></pre>
<p>Here are the results:</p>
<div class="figure" style="text-align: center"><span id="fig:virtual-conf-int"></span>
<img src="ismaykim_files/figure-html/virtual-conf-int-1.png" alt="100 confidence intervals based on 100 virtual samples of size n=50" width="\textwidth" />
<p class="caption">
FIGURE 9.15: 100 confidence intervals based on 100 virtual samples of size n=50
</p>
</div>
<p>We see that of our 100 confidence intervals based on samples of size <span class="math inline">\(n\)</span> = 50, 96 of them captured the true <span class="math inline">\(p = 900/2400\)</span>, whereas 4 of them missed. As we create more and more confidence intervals based on more and more samples, about 95% of these intervals will capture. In other words our procedure is “95% reliable.”</p>
<p>Theoretical methods like this have largely been used in the past since we didn’t have the computing power to perform simulation-based methods such as bootstrapping. They are still commonly used though and if the normality assumptions are met, they can provide a nice option for finding confidence intervals and performing hypothesis tests as we will see in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>.</p>
</div>
<div id="where-does-the-1.96-come-from" class="section level4 unnumbered">
<h4>Where does the 1.96 come from?</h4>
<p>We’ve been mentioning quite a bit throughout this chapter that if the distributions are bell-shaped and symmetric that things will likely work nicely for us. This bell-shaped distribution is commonly called the Gaussian or normal distribution. It has that characteristic shape of a bell that we’ve discussed.</p>
<p>The 1.96 in our formula for a 95% theory-based confidence interval is directly related to the normal distribution. The normal distribution is actually a family of distributions with each characterized by their mean and their standard deviation. The <em>standard normal distribution</em> is one of the most common since it acts as a standardization for all of the other normal distributions. In other words, via some formulas, any value of a normal distribution can be converted to its corresponding value on the standard normal distribution. Let’s take a look visually at this standard normal distribution and the range of different values it can take on.</p>
<p><img src="ismaykim_files/figure-html/std-normal-setup-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>Let’s draw a vertical line at both 1.96 and -1.96 on this plot.</p>
<p><img src="ismaykim_files/figure-html/std-normal-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>Any guesses to how much area is under the black curve and to the right 1.96? The correct answer is very close to 2.5%. Since the normal distribution is symmetric there is also 2.5% of the area to the left of -1.96. Therefore, if we wanted to encapsulate the middle 95% of the values on the standard normal distribution we’d be pretty close to between -1.96 and 1.96. That’s the reason why we choose 1.96 as our multiplier in the formula above.</p>
<p>What if we wanted to get the multiplier for say a 90% theory-based confidence interval? R has a built-in function to help us with that:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="dt">p =</span> <span class="fl">0.95</span>)</code></pre>
<pre><code>[1] 1.64</code></pre>
<p>Here <code>q</code> stands for “quantile” and <code>norm</code> stands for normal. So the 95<sup>th</sup> percentile of the standard normal distribution falls at around 1.65. Let’s check to see where the 2.5<sup>th</sup> percentile falls:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="dt">p =</span> <span class="fl">0.025</span>)</code></pre>
<pre><code>[1] -1.96</code></pre>
<p>This is what we expected above. Close to -1.96 corresponds to the spot that is 2.5% of the way into the values of the standard normal distribution. We’ll elaborate more on these theory-based methods in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>, but this should give you a good start!</p>
<hr />
<div class="learncheck">
<p>
<strong><em>Learning check</em></strong>
</p>
</div>
<p>Practice problems to come soon!</p>
<div class="learncheck">

</div>
</div>
</div>
<div id="ci-conclusion-table" class="section level3">
<h3><span class="header-section-number">9.8.3</span> Summary table</h3>
<p>In this chapter, we performed both tactile and virtual simulations of resampling/bootstrapping to infer about unknown parameters. We also presented a case study of bootstrapping in a real-life situation: the suggested contagiousness of yawning. We used the sample proportion <span class="math inline">\(\widehat{p}\)</span> to estimate the population proportion <span class="math inline">\(p\)</span> and the sample mean <span class="math inline">\(\overline{x} = \widehat{\mu}\)</span> to estimate the population mean. We also explored a two variable problem in our yawning case study. Let’s review these and others again in Table <a href="#tab:summarytable-ch9"><strong>??</strong></a>.</p>

<p>We’ll cover all the remaining scenarios as follows, using the terminology, notation, and definitions related to sampling you saw in Section <a href="8-sampling.html#sampling-framework">8.3</a>:</p>
<ul>
<li>In Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a>, we’ll see an example of statistical inference for
<ul>
<li>Scenario 4: The difference <span class="math inline">\(\mu_1 - \mu_2\)</span> in average IMDB ratings for action and romance movies. This is another example of <em>two-sample</em> inference.</li>
</ul></li>
<li>In Chapter <a href="11-inference-for-regression.html#inference-for-regression">11</a>, we’ll cover an example of statistical inference for the relationship between teaching score and various instructor demographic variables you saw in Chapter <a href="6-regression.html#regression">6</a> on basic regression and Chapter <a href="7-multiple-regression.html#multiple-regression">7</a> on multiple regression. Specifically
<ul>
<li>Scenario 5: The intercept <span class="math inline">\(\beta_0\)</span> of some population regression line.</li>
<li>Scenario 6: The slope <span class="math inline">\(\beta_1\)</span> of some population regression line.</li>
</ul></li>
</ul>
</div>
<div id="additional-resources-6" class="section level3">
<h3><span class="header-section-number">9.8.4</span> Additional resources</h3>
<p>An R script file of all R code used in this chapter is available <a href="scripts/09-confidence-intervals.R">here</a>.</p>
</div>
<div id="whats-to-come-7" class="section level3">
<h3><span class="header-section-number">9.8.5</span> What’s to come?</h3>
<p>This chapter introduced the notions of bootstrapping and confidence intervals as ways to build intuition about population parameters using only the original sample information. We also concluded with a glimpse into statistical significance and we’ll dig much further into this in Chapter <a href="10-hypothesis-testing.html#hypothesis-testing">10</a> up next!</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="8-sampling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="10-hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/moderndive/moderndive_book/edit/master/09-confidence-intervals.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["ismaykim.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
